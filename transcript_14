
Search our transcripts by guest or keyword
COMPANY
Careers
Blog
Shows
Sponsors
Newsletter
About Us
Sitemap
LEGAL
Disclaimer
Privacy Policy
Terms and Conditions
SOCIAL
LinkedIn
Twitter
® 2022 Colossus, LLC. All rights reserved.
Released June 27th, 2022
Invest Like the Best
Kenneth Stanley - Greatness Without Goals
Ken Stanley is a Professor in Computer Science. We cover the reasons greatness cannot be planned, the importance of the individual in a web of disruption, and how to best allocate resources to foster innovation.

00:00:00
01:13:49
Introduction
[00:02:07] Patrick: My guest today is Ken Stanley. Ken is a professor in computer science and a pioneer in the field of neuroevolution. He is also the co-author of a book called Why Greatness Cannot Be Planned, which details a provocative idea that setting big audacious goals can reduce the odds of achieving something great. We discuss that revelation in detail on how to apply it in our day-to-day lives. Please enjoy this great discussion with Ken Stanley.

The Best Way to Change the World
[00:02:35] Patrick: So Ken, we were just together at Capital Camp this past week in Columbia, Missouri, and you gave, I think, what's proven already to be the most popular of the presentations during the week mostly because it really got people thinking, and we're going to try to replicate that phenomenon here today. I came across your work because of the book that you wrote with your co-author Joel called Why Greatness Cannot Be Planned. Then I'll probably refer to a few things that I read in the book throughout our conversation as sparks for our talk. There's one very early on that I think I'll start with that'll allow you to introduce the broad idea of your work, which is that sometimes the best way to change the world is to stop trying to change it, a provocative starting idea. Maybe you can use that as a jump off point to explain your research, your work, and its core thesis.

[00:03:18] Ken: That statement is a common saying. You hear things like that sometimes. The best way to find someone you love is to stop worrying about love or you hear these cliches sometimes. I think that that reflects that somewhere within our culture we recognize that there's a bit of a problem with setting goals and strictly adhering to them with this belief that that's ultimately going to cause you to get what you want. Yet what the book is about is that we have a tendency in our culture, a strong tendency, to basically design everything that we do around exactly that archetype, which is that let's set a goal, stay on our objective, and then let's set some metric so we can decide how close we're going to that goal, and then let's put all our effort into just moving directly in the direction of the goal. We believe somehow that this is going to lead to all the things that we need and want to accomplish, keep us ahead of the curve, avoid disruption, all the things that we're worried about, that this is the formula, basically, for everything. What the book is about is that it actually doesn't work. It's an interesting allegation to say that this doesn't work because it's not like most controversies. Most controversies in our culture are very controversial. There's already sides. People are debating these things, and they're often very political. This one, though, there's no debate right now. Nobody's talking about this. There are no sides.

[00:04:45] Patrick: How bad objectives are?

[00:04:47] Ken: Yeah. There's no protests out on the street about getting rid of objectives. I feel like this is a hidden problem, but I think the book we wrote, Joel Lehman and I, we felt after we ran into this principle, which comes strangely from artificial intelligence research, comes from a circuitous direction where the serendipity that we fell into noticing this that has social implications way beyond just artificial intelligence research. When we noticed this, we felt that this is actually a really serious problem, a serious underlying social problem because the mechanism that we're using in our society to deal with all of these huge challenges that we have is exactly this principle that is flawed, so severely flawed. So it's going to cause us to go astray over and over again. This goes all the way from a personal level where you have goals in your life which have been set since you were very young and encouraged by your parents and the educational system, all the way up to institutions like corporations and top of the government itself. All of these institutions and individuals are using goal-setting as the one heuristic for getting to high-level achievement. So the book tries to both say, "Okay. Here's why this is something we shouldn't believe in with such confidence that we do and what are some of the alternatives," since that's the natural next question because it seems almost like, "Then there's nothing I can do," or "The only thing I can do is just be random," and that's not really the case. There are alternatives, which is why serendipity does happen. Chance favors the prepared mind.

[00:06:23] Patrick: The idea here is a big one, that we're a progress-oriented society and always have been, and that our principal tool for achieving progress, the objective and the achievement of the objective is in some ways deeply fundamentally flawed. I want to be very clear, because you are in your book, about what kinds of objectives you mean. I don't think you mean the very simple, straightforward things. I think you mean the BHAG, the big, hairy, audacious goal. Can you just make sure that we level set on the kinds of things that your work addresses and maybe the kinds of things that it doesn't?

[00:06:56] Ken: Thanks for putting in that caveat because that's really important, I think. I can lose a lot of people by just starting out with this crank-like claim that we should have no objectives, whatsoever, in our lives like, "Let's all just do whatever we want." Okay. That's going to appeal to some very small minority, but that doesn't sound practical to a lot of people, and that's true. The claim here is not that we're just going to dump all objectives. Some objectives are principled. Yeah, I would agree with the distinction you're making. It's like BHAG ideas. Those are the ones that are of concern. So if you have what I call modest objectives in your life or if institutions have those, I think those can be reasonably pursued as they generally are. I want to improve my lap time or something by exercising at the track or something. That's reasonable. We know that, and people have done that very reasonable things. It's not extremely innovative or maybe we're going to upgrade our software to the next version. This has been done numerous times as a corporation. This is not a hugely controversial thing. We can set that objective and we can move towards it. We can even set metrics and things like that.

What I'm talking about is more related to things like innovation and discovery and disruption, blue sky stuff, some extreme examples of things like cure cancer or achieve artificial general intelligence, super ambitious things, but even things that aren't as ambitious as those would fall under this category, basically stuff where we just don't know how to do it, which is a huge, huge range of things that are very important to us, things like bringing down inflation or something like that. So that's not the same as curing cancer, but the problem is that we don't know what exactly the stepping stones are that lie along that path to doing those things. As soon as that's true where the stepping stones are mysterious, especially if there's several of them that we have to go through on the road to where we want to go, then this principle that I'm talking about, which I might call the myth of the objective or you call it the objective paradox, where it's setting an objective actually hurts your ability to get to it, so that's a paradox, then it starts to come into play with those kinds of things.

The Story of Picbreeder
[00:08:44] Patrick: In the book and in the presentation you gave last week, there's a key central example that, like you said, you stumbled upon via some of your own research. I would like to walk through that story. I want to just plant the key idea before we do that with another quote from the book, which is that, "Almost no prerequisite to any major invention was invented with that invention in mind." You used that term stepping stones, the things that we combine. You gave the example of vacuum tubes and computers. People working on vacuum tubes weren't thinking about computers, and there's a million examples like this. So I just want to plant that idea out there. The stepping stones thing not resembling the final invention is the reason why it can't be so deterministic, and here's our objective, set up the steps between now and there. Maybe you can start to introduce that concept via the Picbreeder example that I think was the way that you originally alighted upon this idea in your research.

[00:09:31] Ken: It's neat because, in a way, this is a story of serendipity, which is about serendipity. I mean, basically, this pic breeder just serendipitously led to this insight. Picbreeder was an experiment that I was running with my lab. I was a professor at the time at the University of Central Florida, where we allowed people on the internet to go and breed pictures. I know this is a major digression from what we were just discussing. We were discussing all these important things and we're talking about breeding pictures. So how do these things connect? Breeding pictures, it is a little esoteric from general societal concerns perspective, but it's basically about searching through a space in a way. This was an opportunity for us when we were doing artificial intelligence research to crowdsource. Crowdsourcing is really interesting. Let's say you to take people on the internet because you've got access to potentially thousands, millions of people and have them try to do something collectively. Wouldn't have been possible in the past if you didn't have access to the internet. What we wanted to do was to crowdsource people, to search through the space of images or pictures and what that meant. So we used breeding. So basically, what it meant was that you could take an image, say a blob or something, and in fact, the site would start you off with random blobs if you started from scratch and you could say, "Look at some blobs and you could pick the one you like the best," just like you might if you were breeding horses or dogs, "Pick the one you like the best." You might have different reasons or criteria, but whatever your criteria is it's fine, and then it would have children.

So it's a little strange. It sounds strange. The picture has children, but this is inside of a computer. So if you think about it, why not? The picture can have children. The children or the offspring of the picture are like any other children. They look like it. They're not exact duplicates just like if you have children, they look a little bit like you. They're not exact duplicates of you or your spouse either. That's the case here. So then what's cool is that then you can see that if your picture that you chose has children, then you can look at the children and then you can pick from those children which one you like the best. You can see that this is in effect breeding. So then out of those, you pick your favorite there. It has children, and then you get to choose from those, and then so on and so forth. You're basically iterating generations of breeding, where it goes depends on what you choose up to you. To tie this back quickly, what does this have to do with anything? If you think about those images, they're basically a metaphor for discovery in general. If you think about like what you said about vacuum tubes and computers, computers are a discovery, vacuum tubes are a stepping stone on the road to that discovery. So somebody chose to use those vacuum tubes to try to build a computer. When it comes to image breeding, if I see an image that looks like something interesting, and then I choose to breed it further and then I get something else, maybe a picture of a skull, which actually was discovered, then I basically used that stepping stone to get to a discovery. So somehow, there's a metaphor, an analogous metaphor here.

What's cool about this site, what made it, I think, compelling to me was that because it's crowdsourced, what we allowed people to do was to come in and look at what other people had bred. So there's this big database and it's being displayed in a natural way, a way that makes it easy for people to see what's been discovered to surface things that are interesting. So those you can think of as stepping stones. You might see a butterfly or a face or something like that. Then someone who sees that is allowed to instead of starting from scratch, instead of starting from blobs like you would if you were starting from scratch, they can start from your discovery. If you found a butterfly and somebody wants to breed new butterflies, then no problem. They don't have to start from scratch and get to a butterfly. They can start from your butterfly and then breed from there. It's called branching. So that means that people are building off of the discoveries of their predecessors or you could think of as standing on the shoulders of their predecessors, which is, again, it's a really nice analogy, I think, to how human innovation proceeds in general, where someone invents something, discovers something, comes up with an idea, and then someone else that they might not even know later in the future goes back in history and sees that thing and realizes this could be used for that, and it transfers that idea over and it becomes a stepping stone to something else. This has been going on for as long as civilization, basically is civilization. That's what basically causes civilization to happen. So pic breeders are a microcosm of that, but here's where the thing that leads to the insight that's profound and to me was shocking was that after running this site for a couple years, so this is a long time, and letting people just breed and discover things and they discovered all kinds of things, butterflies and cars and planets.

[00:14:01] Patrick: We'll put a link in and a collection to some of these. It's really staggering, the things that you see that started with black blobs.

[00:14:07] Ken: Yeah. Yeah. So you'll get a chance to see it. They found all this stuff after a couple years of watching this. Then what we found was that underneath the hood, we were able to look at how. If you think about just for a second, just think about why Picbreeder is fascinating. At first, it might seem like a toy or something. What is it actually for? People are playing around and breeding images, which have no purpose other than just that they're images, but actually, what is, I think, profound about having something like that is that it is basically a history of discovery in all of its minute detail. Every little thing that everybody decided to do throughout the history is recorded. We don't have artifacts like that. We don't know every step of every invention that's ever been made. A lot of it just happened inside of someone's head. So this is not recorded, but Picbreeder is one of the few things, maybe the only thing where every single step of everything is recorded completely. So that meant that after a couple years, we could go back and find out what actually explains how everything was discovered, and I turned out to be, I think, shocking. The shocking revelation was that in almost every single case, more than 99% of cases, if you looked at something interesting, like a car, for example, or a butterfly or a bird or whatever it might be, if you go back in its history and you look at what were the steps that led to that thing, the steps look nothing like it at some point back. Right before you get to it, it might look like it, but if you go back far enough, you will find a stepping stone that looks absolutely nothing like it in 99.9% of cases.

Why is that a revelation? Well, the problem is that if you think about it, what that means is that the only way to discover any of these things was to not be trying to discover them. Now, usually if you say things like that, that sounds like some new age statements, discover things by not trying to discover, and that's mystical or something. Now, think about this. I'm not talking in the new age perspective. This is an empirical observation. This is actually what happened. The people who discovered these things who are responsible for the stepping stones that led to the discoveries were not actually trying to discover those things because if they had been, then they wouldn't have chosen the things when they had their selections. They had these blobs they could look at. They could choose one of them. They wouldn't have chosen the ones they chose if they were trying to get the final product. For example, you have a case where there was an alien face that led to a car. Who would choose an alien face if they want a car? That would not be a good idea, but what happened was the wheels of the car, which was depicted from the side, actually derived from the eyes of the alien face. Again and again and again, you see this phenomenon that in hindsight, you can see what happened, but looking forward, you would never imagine that these connections could be made. This shows, in fact, it's true in Picbreeder that you can only find things in the long run by not looking for them. You need to take your eyes off the ball in order to be able to accept the stepping stones that ultimately make finding the ball possible, which I think is totally contrary to our culture, to our way of making discovery, the way we think things should be done, which is always objectively driven. So the connection that I need to make, I think, beyond that is to justify why I would extend from that discovery to real life.

[00:17:21] Patrick: If you think about the power of these images, most of them were achieved across what I'll call a modest amount of generations. We'll talk about AI and machine learning a little bit later on, which is so interesting because almost all of it has an objective function. It's almost all objective-based. So that'll be an interesting part of our conversation, but when you put up the number of generations of breeding to get from a blob to a clear bird, let's say, it was only 80, 90, 40, 100. It wasn't that many iterations. Then you showed us a skull, a picture of a skull, and really drove the point home by describing, "Okay. Now, let's imagine this specific skull or one very close to it is our objective." Could we get close to it across way, way, way more generations and actually targeting it? Maybe you can describe that experience because I found that to be a powerful nail in the coffin.

[00:18:10] Ken: So basically, we took this and we said, "Let's try to drive the point home and also just see if we can validate this hypothesis that you can only find things by not looking for them by actually looking for them explicitly." Just to make it fun, I think this twist makes it fun, let's look for things that we already saw were discovered. That makes this crazy because it's like we know that these can be discovered in this space. Like you said, I think it is an important point that these things were not discovered with a lot of compute, so to speak. If I recall, I think it's 72 generations, might be 74, 72, 74 steps or iterations. That is just ridiculously low. When you think about it in terms of compute, of course, these are humans making these selection steps, but in machine learning, modern machine learning, it's pretty reasonable to have millions of iterations to get to something meaningful. Here, we're talking about dozens. In some way, that says these are easy. These are not hard discoveries. In some sense, they're still impressive because of the fact if I just randomly choose blobs in blob space, in the space of the Picbreeder, you'll never find anything. 99.99999% of the space is just garbage blobs. So these are still needles in haystack, but what's weird is that the needles in the haystack are discoverable within a few dozen steps. One conclusion you might draw naively would be that, "Oh, they can't be that hard to find." The skull is let's say 74 steps trivial, basically, from a compute perspective. So let's set up an experiment and see. So what we can do is we can say, "Let's get an image matching algorithm," which are available, which basically tells me if I show this algorithm a blob, I input this blob and I ask it to compare it to the skull, it'll tell me how far away we are, how close is this image to a skull.

That comparison will help me because when I show a bunch of blobs, I can just have it automatically pick the one that's closest to the skull. It's really simple. Then every iteration can be done now by the computer instead of by a human. So we can automate it. Good old fashioned machine learning here. We just automate Picbreeder. No more humans in the loop, and we'll just automate it to go to the skull. I think to me, this sounds like a worthy adversary. I would be worried this might actually work. It shouldn't work though our hypothesis is correct because our hypothesis here is that you can only find things by not looking for them. Now, this is explicitly looking for the skull. This is a metaphor for how we do things in our culture. So we say, "This is our goal. This is our OKR. This is what we're going to achieve this quarter, and now we're going to work towards it. You're going to give me a metric. In this case, it's skull matching. Let's match the skull picture," and then you're going to cut off branches that don't seem to be maximizing that metric and go by the branches that do seem to be maximizing the metric and just move towards the skull. We're going to do that now explicitly. We gave it 30,000 steps. This takes about 74 steps, let's say, for the first discovery by a human. Now, we're giving an automated algorithm, 30,000 steps, just for fun, just in case, I don't know, it needs extra time. We'll give it way extra time, orders of magnitude. What happens? Failure every single time. We ran this dozens of times. It's every single time failure.

It's also fun to look at the failures because you can see it's trying. You see it shadows. It's like somebody stumbling, almost getting there but not quite. Well, it's not even close, but it's like getting the silhouette shadow of what it wants, but it can't get even close. It's just fascinating. That's much more compute. It should be able to eventually overcome it, but the thing is that it highlights the reason that this is happening in if you look at it. Why are all discoveries happening this way in Picbreeder? It's actually because the world is deceptive, which means that the things that lead to skulls don't look like skulls. This is the fundamental insight, which is not being recognized across society. It's that the things that lead to the things you want don't look like the things that you want. There's actually a name for this in philosophy. It's called the like causes like fallacy. I think it's from Mills. We all seem to assume. It seems to be almost like built in to us biologically that the things that lead to what we want are going to resemble what we want. I don't know why we all believe this, but it's not how the world works. If you think about it, that makes total sense. If the world actually worked that way, if the like causes like fallacy was actually true, actually things do resemble where you want to go, we would solve all that problems.

[00:22:19] Patrick: Cancer would be cured, yeah.

[00:22:21] Ken: Exactly. It's like it would be obvious what to do. We'd always just choose the thing that's getting closer to the goal and then it would eventually get there, but if you really think about it, how could the world work that way? That's a ridiculously naive view of the world. The world is complex. What does the word complex even mean? If that was true, then there would be no such thing as complexity. Complexity basically means that everything is circuitous and hard to understand. Hard to understand means that the things that lead to the things you want aren't the things you want. They're very complex. So you need to do things like work on vacuum tubes to get to computers because vacuum tubes are in the first computers, even though vacuum tubes don't seem to, on the face of it, have anything to do with computers at all. If you're just working on vacuum tubes 100 years before computers, what does that have to do with computation? Nobody working on them was thinking about computation, whatsoever. This is true, like you said, when I made this statement, which I think is just intrinsically controversial.

None of the stepping stones to any major invention were invented with that invention in mind. That's why this is true. I think that that's hard to digest that statement because it sounds absolutely insane, but it's actually true. If you go back far enough and you look at this prerequisites, the stepping stones, you will find things where you could never predict. So the problem is you are absolutely dooming yourself. If you are trying to find things that look like where you want to go and you're trying to go a far away, you're screwed. You'll never get there. That yet is how we're running our institutions. This is institutions like the granting agencies, like the National Science Foundation all the way down to your innovation lab inside of your company over and over again guided by objective principles. What should we do about the fact that this actually doesn't make any sense?

The Role of Individuals Versus Consensus
[00:24:01] Patrick: There's one piece of this that I love that hasn't been mentioned yet, which is the role of the individual and their decisions relative to I'll call this heterogeneous decision making versus homogeneous ruling by committee or something or making choice by committee. Talk about the importance of the individual and their choice in this web of invention and disruption.

[00:24:20] Ken: Yeah. This is a funny thing. It's true. This is another very popular mythology, I think, in our culture is let's get together and collaborate, bring all the smart people into the room. It's not just like, "Let's get interdisciplinary collaboration. Let's get the computer scientists sitting there with the economist." All these things are very exciting to us. I just want to say I'm not saying we shouldn't have collaboration. That again would be this crazy cranky thing to say. What I do want to get to what you're asking about is that collaboration itself also is subject to a number of caveats because of the insight about the paradox, the objective paradox, and that means there's a right way and a wrong way to think about collaboration. It's quite dangerous. We tend to do it the wrong way. The issue that comes up here is that if you look at Picbreeder, I think something that's very intriguing about what happens in it is that once somebody sees a stepping stone on the site, so if you recall, like I said, all the discoveries that other people had made are made available for you. So what it means is you are seeing a history of stepping stones when you go to this site. You don't have to start from scratch. If somebody found a butterfly, you can start from their butterfly.

When you come in and see that butterfly, that is a point of collaboration. It's implicit collaboration, but it is collaboration because somebody else did work, they found the butterfly, and now you're building off of that work. So collaboration is happening. However, the moment you choose to continue or what we call branch from the butterfly to breed it further, you are on your own. This is a very unique thing. At first, it sounds like, "Oh, well, what's the big deal? You're on your own, okay," but think about it. We almost never allow people to do that in collaborative situations in our culture. We always bring people together and move towards consensus almost immediately, but in Picbreeder, it's not like that. Instead, you choose the thing you think is interesting and it was your choice and nobody else was involved in that choice. Now, think about this compared to, for example, I was a professor for a long time. So I think a lot about asking for grants, science grants. That's like picking an image. It's like what project do I want to pursue. You come in and you see a butterfly and you want to pursue the butterfly. It's like you're sending a grant proposal to the NSF. You think something interesting will happen if you choose this butterfly, but the thing about the NSF is now it's going to go to a committee. I am not allowed to just go off on my own and work on that butterfly now. There's going to be a committee that thinks about the decision that I'm making, and I have to justify usually objectively in the sense that I'm going to have to say where it's going to lead.

What are you going to get by doing this butterfly? That is not how Picbreeder is. You are on your own completely, and not only are you on your own by choosing the butterfly, you're on your own every single step of the way until you publish the thing you discovered. So there's no interference, whatsoever, and you're just on your own. Think about the difference between that and the way we run things where it's basically you come into a room with all these people, you bring up these ideas, you have this discussion, you try to come to consensus. All the crazy things you would've done are basically cut off at the start by this surge towards consensus, which is going to lead to what I would call convergent consensus because we're trying to move toward convergence very quickly. What you'd understand from Picbreeder is the proliferation of the stepping stones that gives the power to the process. The reason that I can get to cars, there was a discovery of a car which came from an alien face, was because of the discovery of the alien face. No one would ever think that you needed an alien face to get to a car, but the alien face is there not because somebody was thinking about cars, but because there is a general culture inside of Picbreeder of proliferating stepping stones.

This is not generally how we run collaborative systems because we run them by consensus, which is the exact opposite. That's about pruning out stepping stones. People start generating things and then we start saying, "No, no, no. Committee doesn't like this. Committee doesn't like that." We then converge to the thing, which is basically the consensus basis of current thinking, which tends to be dogmatic and tends to be status quo and everything that we basically want to get away from, and then all these radical stepping stones, which are the interesting things which could lead to places we're not expecting for the very reason that the things that we'd want to get to don't look like them so we need the radical stepping stones are the things that we cut out. You can see from this theory or philosophy way of looking things that a lot of the way we run collaborative systems is just totally kneecap at the start, and also should, I think, be rethought.

[00:28:31] Patrick: Can you describe when you put a consensus mechanism into this experiment, the outcome falling to all this? I promise we're going to get to some of the bigger implications here in a minute, but this simplified example is this so damn powerful for how we all are going to spend our time in our lives. Maybe just describe the outcome when you insert consensus mechanism into how these generations progress.

[00:28:54] Ken: This is super interesting, and it's funny because it's just a coincidence that this happened because there was another project that was launched around the time of Picbreeder called the living image project. It had nothing to do with me other than it used basically the same in coding under the hood as Picbreeder. This is nice because it creates a controlled experiment by accident because both Picbreeder and this other thing, the living image project, have this underlying coding that's the same. So what that means is in principle, they can achieve the same thing. They could find similarly cool stuff in principle, but there's this one difference, which makes this very interesting as a comparison, which is this living image project did work by consensus. I mean, the reason it did is because I think it's because there's this cultural assumption just like riding on top of that. They're like, "This is a good way to do things. Let's have a vote."

So basically what they said is, "Okay. Here's what we're going to do. Just like Picbreeder, there's these blobs, they're arranged on the screen, you can see all these blobs, and we're going to pick one of them. That'll be the parent of the next generation of blobs." However, the difference from Picbreeder is that the choice will be made by a vote. So over the course of a week, people will come in and it would turn out basically hundreds of people would come in, and they would vote on their favorite blob and then we'll choose the one that gets the most votes. To a lot of people, this is really intuitive. More opinions are better than one. Let's use the crowd to decide what to do, but consistently with what I just argued, the result are starkly different and terrible in comparison. I don't mean to cast any dispersion on the living image project. I think it was a cool idea to try it. It really helps to illustrate. The problem here is that you get a washout effect. Imagine you come in, okay? There's hundreds of people coming in. Imagine you like butterflies and I like cars. Now, what's going to happen when we vote and we're just looking at blobs? The blobs don't look like butterflies yet and they don't look like cars, and you want a butterfly and I want a car. What is going to happen? Complete washout is what's going to happen.

There's no way you're going to get enough people on your side. You don't even know. We don't even know what each other are doing or have understanding of how you even get these things. So what's going to happen is you get this mildly aesthetic blobby pattern type of consensus. We get the mildly, most pleasing blob aesthetic, and then that's going to happen at every iteration because there's another few hundred people voting at the next iteration and another few hundred, and after thousands and thousands of, I think it was 25,000 votes, you can look at the top ranking, all you have are amorphous rainbowy blobs every single thing. I think it's just stark and shocking. Even though it's in this totally obscure genre of stuff like breeding pictures, I think it should give us all heart palpitations because we're running our culture this way.

Vacuum Tubes and Other Innovations
[00:31:23] Patrick: You mentioned vacuum tubes. What are some of the other favorite examples of this happening in the real world because we have been talking about a low dimension, quaint, back water part of the internet, messing around with pictures? When we zoom out to the real world, what are some of your favorite examples that have actually happened?

[00:31:43] Ken: I know you already brought it up, but I think it's one of my favorite examples from the real world because it's very thought-provoking. It's the vacuum tubes and computers because it goes over hundreds of years, and I think it's very helpful to illustrate what I'm talking about. I think we have this myth, this tale that we tell about almost everything has ever been achieved by humankind, which is very objectively driven, the narrative of achievement. It's like some amazing visionary just sat down and said, "We're going to overcome all the obstacles and just do this amazing thing," like make a computer. Let's think about that, for example. When that was done in the 1940s, there was a military motivation at the time we needed these computation machines and so forth. We had reasons we wanted these things, but you could tell the story as if it's this objective triumph. We got together the best minds. They put their effort into it. They build this thing. It just happened. That's just the story of human achievement. What a great thing we should all celebrate.

The the thing is you're leaving something out. We're leaving something out in those kinds of allegories. There was stuff that happened before that. The story doesn't start where it starts, and that makes the story extremely misleading because that's not actually the story because there were things that we needed to build that computer, just as there were things we needed to build the space shuttle and so forth, all your favorite stories of human achievement, airplanes, what have you. It'll be the same thing, but to focus on the computer, the thing that we needed, one very key thing is a vacuum tube. Now, today, computers aren't made out of vacuum tubes, but in the 1940s, the first computers had vacuum tubes in it. The first ones that actually worked and were used and produced, not mass produced, but produced, and actually used for purposes, they had vacuum tubes. So the thing that really made it possible to have this narrative about, "Oh, there's this amazing visionary," was the fact that somebody already had invented vacuum tubes.

[00:33:26] Patrick: What is a vacuum tube? I don't even know where that is.

[00:33:29] Ken: A vacuum tube is a electrical device. In the early computers, it was used as a small unit of computation. Early on, they were trying to understand properties of electrical devices in general. They weren't thinking about using it for computers at all. It allowed people to understand what you can do with electricity. It goes back to, I believe, the 1700s, basically glass tubes with vacuums, where they could run electrical currents through them and learn about their properties. If you go back to those times, which is going actually hundreds of years before you get to computers, what you find I think is very interesting, which is that you find people who are interested in electrical properties who were not thinking about computers, but these people are an essential part of the story of computation. That's the part that's left out of the narrative. The hero of the story is partly the vacuum tube researcher, but the vacuum tube researcher has not a single thought about computation. This is where we should get worried again because if you go back in time, go back to the year 1850, roughly around a hundred years earlier before the first computers, the Eniac computer, you could find these people who were doing that work, and what we could imagine a thought experiment here where we could approach those people because they're super smart. They're the hackers of the day.

So we could go to those people and we could say, "You're doing something interesting, granted, but there's actually something much more interesting you could be doing, which is you could build a computer. What the heck are you doing with this boring vacuum tube stuff? Let's build something like a computer. I can tell you a little bit about what the vision of the computer is. Now, why don't you think about that instead? Let's get you guys together and do that." If you think about this thought experiment, it would be a horrible thing to do because you just pulled all the people off the stepping stone that you needed. If you think about this alien face was used to get to a car in Picbreeder, if I took the person who is working on the alien face and pulled them off of it in the middle of their session and said, "Actually, I'd rather you try to read a car. That would be more interesting," then you'd have neither. You'd have neither an alien face nor a car. It's the same thing with the vacuum tubes and the computers. You pull the people off the vacuum tubes and you make them work on computers. Well, you just took out the stepping stone that leads to computers. So you can't do either. So we would have neither vacuum tubes nor computers. This is, I think, a dramatic illustration of the fact that Picbreeder does exist in real life and that not respecting that is devastating. You absolutely destroy innovation if you try to control it in the way that we do try to control it. It's just serendipitous luck that these stepping stones got front. Luckily, they were not part of some institutional attempt to control where we're going because if they were, they wouldn't have happened.

[00:36:02] Patrick: You start to see this everywhere, whether it's induction coils with air travel or mold and penicillin or Viagra coming from a hard medication. I mean, all these weird things were rather than someone saying at the end of an invention cycle, "I've done it," it almost always seems to be like, "Huh, that's funny. Something weird is going on. There's some other use." I even remember, I think it was Nintendo. There's some great line about how Nintendo proceeded with its innovations, and it was something like lateral innovation with withered technology, combining old random stuff together to produce some new outcome, which I think brings us to the prescriptive. So we were talking about the key observation here. The steps don't resemble the final thing so it's almost impossible to actually achieve. Like you said, I love the delineation of we don't know how to do something is the goal that we're talking about here, not something that we've done in the past, and we need to get practical here. So it's both scary and exciting that the greatest things that any of us might accomplish are not something that we can imagine or something that we could accomplish through just a linear progression. So I'd love to describe what you think this means for how people should behave, especially ambitious people that want to achieve great things or affect big change or create wonderful innovation or disruption, all the things that everyone listening probably wants to do. We've just been told we shouldn't pick it objective. We should just mess around. So what does that mean? I especially liked how you talked about objectives being very future-oriented, whereas your prescription being maybe more past-oriented in terms of interestingness and novelty. Let's start to talk about how this might actually affect what we do with our lives.

[00:37:35] Ken: Yeah. That is the natural question then. How should we conduct ourselves given this critique of how we generally do conduct ourselves? I just wanted to add one little point just to emphasize how broadly applicable this is that we're not only talking about technology, right? The examples I've been giving are very technical, computers or something, but this is about genres of art. What leads to what in art? What leads to what in musical genres? What economic systems, political systems, financial strategies? Everything is about this. It's not even just about things we want to accomplish. It's about things that we don't know we want to accomplish, but we would want to if we knew they could even be possible. That could be what you're going to do in your life. You may create something, come up with some idea that you weren't even aware was something worth trying to do but turns out to be awesome. So all these things fall under the umbrella of this idea. Okay. So how should you conduct yourself? It seems like a lot of people jump immediately to the word random. Basically, you're just saying, "I should just be random." It's like, "I'm going to cry. This sounds terrible. I don't want to be random. I'm a smart guy. I can do things for intentional reasons."

I just want to start just to say this is not suggesting that anybody should just act randomly. That's not a good strategy, obviously. It's not an alternative strategy at all. It's just as dumb as the original strategy, but let's acknowledge, though, that the original strategy is also dumb. One thing that you have to digest here, which I think is really hard to accept, is that there is no good strategy to achieve a specific thing that we don't know how to do. There's just no principled way to do that. What I can give you advice on is how to maximize the chance of achieving something useful, but not a specific thing. So this is the pivot that you have to do, I think, when you're talking about innovation. You have to understand that a successful inventor, somebody who gets to places that we haven't gotten before, is somebody who's open-minded and willing to keep a repertoire of stepping stones around without knowing which one is going to be the payoff. You have to drop this idea that there's this one thing which is the goal and we're going to have this metric-based assessment thing, and we're always going to be moving towards it. It just doesn't work, but you can be principled if you're trying to maximize opportunity to have some success, even though we don't know what that success will be.

The reason you can do that is because if you think about something like Picbreeder, it's basically like a stepping stone collector. That's actually what makes the system powerful, and stepping stone collecting is anything but random because if you think about it, it's the stepping stones themselves that lend the power to the system and the stepping stones are there because they're interesting. They're not random. You go to Picbreeder and you see a skull and a butterfly and a car. There's nothing random about any of that. A random thing would be like a blob, but you see these things that have meaning. So they actually give power to the system because the thing is that things that are interesting are stepping stones to other things that are interesting. That is the true structure of the world. That's the structure of search spaces is that when you find something interesting, it has a potential. It's not just interesting for what it is now, but for what it leads to. To give a concrete example of that, sometimes I think about the iPad. The iPad is clearly interesting in its own right in the sense of the things you can do with it. One of the things that to me makes the interestingness of the iPad real is the fact that there were these lines snaking around the block when the first iPads came out. What I like to think about is why. Why were lines snaking around the block for people who just wanted to get the first iPad? I would submit, at least I believe, that it's not just because of what you could do with the iPad, which is cool enough as it is, it's because almost everybody saw that it's a stepping stone. What was interesting about the iPad wasn't what you could do with it, it's that we don't know all the things that you might do with it that we don't know yet. It just opened up an entire new world that we don't know about. That is a powerful stepping stone.

Human beings understand stepping stones. That's one of the reasons we shouldn't be so scared at the message that I'm giving here. This is actually one of our special skills. So there's basically two pieces of advice I would give. One is collect stepping stones and honor interestingness. That is a system that we need to establish. You can do that as an individual and we can do that as an institution. We can actually try to explicitly do this institutionally and we don't, and it's a very interesting opportunity, I think, because it's so little studied. It's like a low hanging fruit, I think, that's ripe for exploitation. The second piece of advice is the more visionary angle, which is to recognize stepping stones when they snap into view for the first time. This is what I think happens in the misleading narratives that usually are characterized as objective triumphs. Think of the iPhone. Did Steve Jobs just sit there and say, "Okay. We're going to build this crazy thing. It combines a phone with a computer, and blah, blah, blah, sits in your hand"? This genius, he just saw this a lot far off vision of doing something like that. That's the narrative we usually get for something like that, but I don't think that's the actual truth. The real thing that happened there was he was the first person to recognize that all the stepping stones had suddenly been laid to make that actually objective possibility. Things that were objectively unrealistic suddenly become possible when the stepping stones are laid, but you need to keep an eye on the stepping stones to know when that moment happens. We see this mistake happen over and over again, which is when vision trumps stepping stones.

It's like self-driving cars. We heard as far back as, I don't know, 2016 or so, right around the corner next year, that is the false visionary type of situation where it's like somebody's being really ambitious, but the stepping stones haven't been laid. You have a false understanding of where we are and you think that the stepping stones are there, but they're actually not. It's going to take a while. I'm not saying they'll never get a self-driving car, but I'm saying they weren't there. The stepping stones weren't there in 2016. If you invest a huge amount of money and so forth at that point in time, you are looking at some serious risk and loss potentially, and people did. I mean, there were a whole self-driving divisions that were created and then later sold off because they didn't pay off, and it's because there was this false subjective narrative. There was the ignorance of the problem that the stepping stones have to be laid. It's like, could we have had computers in 1840 something instead of 1940 something? No, it'd be insane to launch a project like that at that time or could the space program have been in 1900? It's like, "Well, these people were so great and so patriotic and so thoughtful. To launch this thing in the 1960s and they succeeded," but you're missing the fact that that would've been an idiotic insane thing to do in 1900. What was really genius about it was that this was something that was just timed perfectly when all the technology was available suddenly and it wasn't 10 years earlier. That is another thing is keeping an eye on the stepping stones. I think both are things that we can do, maximizing stepping stones and proliferating them intentionally based on interestingness, and also keeping an eye on when things snap into possibility that weren't before.

Stepping Stones for Humanity
[00:44:17] Patrick: It's fascinating to think about some of the general purpose stepping stones. I was listening to a review of Titan, the John Rockefeller biography, and you think about like whale oil for street lamps going to rock oil for kerosene, again, just for street lamps, and then all the things that it led to or the microchip or, I mean, all these things are really impossible to imagine where they go once they've been proliferated. It's pretty cool to think about searching for them. The skeptic in me thinks of, is sitting here replaying the scene from Apollo 13, which is great example of the famous phrase, "Necessity is the mother of all invention and what is necessity, but an objective." So in Apollo 13, you've got the guy saying, "In order for these guys to breathe, we've got to fit this into this using nothing but this," and they solved the problem. So they've got a near-term objective. They don't know how to do it, so it meets our criteria and they fix it. You hear this over and over again like during war. All this stuff gets developed because it's required to win. So how do you think about that phrase, which seems to maybe throw a bit of a wrench in the works of our discussion, necessity being the mother of all invention?

[00:45:19] Ken: There's maybe two things. Obviously, the first thing is that sometimes when you're in a desperate situation, the stepping stones are there to do what you need to do.

[00:45:29] Patrick: You just become aware of them.

[00:45:30] Ken: It wasn't necessary to think of them. It's not just that there was this cool thing you could have done but you didn't think of it. It's like you really didn't need to think of it. There's no need to think of it. If there isn't some catastrophe on the space shuttle or something, then you don't need to think about being innovative about how to get oxygen. It's not a problem. The stepping stones are there, and we can do this. If they weren't there, forget it. It doesn't matter how many geniuses were in the room. I could use that, and that's part of it. That's where we get some of these narratives from because it's actually the stepping stones are there. So it's actually not that far down the horizon to get to these things. The other side is I think interestingness as a really important topic for us to get deeper into and address. When you think about something like war or the necessity of invention in war, I think what is happening that is still instructive there is that we recalibrate the things that we find interesting, depending on what's going on in the world around us. That is a valid thing to do. We understand during a war there are certain types of things that really matter. It's a whole rich tapestry of things. It's hard to even articulate exactly what those things are, but there's this large set of things that are related to war, helping people who have been injured related to destroying things, whatever it might be, which then just become more interesting than they were just because of necessity. It's not the same as having an objective, I think, and I think that we can focus on areas, artificial intelligence, for example, the fact that there's a lot of investment going into artificial intelligence right now, obviously, billions of dollars because we recognize it's really interesting. That's different to me. Although other people wouldn't interpret this way, but this is against the conventional interpretation, but to me, we're investing in the interestingness not the objective.

Artificial intelligence is a far off goal like AGI. It's what people in the field would call it, artificial general intelligence, this human level, amazing machine or something. When I think about that, I think that is too many stepping stones away to realistically invest in. We have no idea what the stepping stones are that are going to be leading to AGI. It doesn't mean we'll never see them. We just don't know what they are yet. As an investment target from an objective perspective, I think it's not very principled, but it still makes sense to be interested in the area of AI, the view of AI and I am personally interested in it. So not hypocritical for me to say it, but the reason it's interesting is because it's pretty clear to me. If you look at things that are AI adjacent, things that relate to computers doing computations that have some alignment with what humans do in their own heads, there's millions of applications there that are just extremely valuable and interesting, and those are the next stepping stones in the chain. So opening those up is going to be cool, whether or not it leads to AGI this far off thing. By thinking that this is an important subject area, I'm actually refining my interestingness sense, and the interestingness sense is what we should be, I think, talking about in the context of what I'm saying leads to innovation because it's the thing that registers the stepping stones. It's like, "How are you collecting this repertoire or this archive of stuff that you can jump off from?" The archive gets more powerful the longer it runs, the more stepping stones we have. That's why from today, the year 2022, we can get to more places than we could in 1922 because our archive is more powerful.

This word interesting is basically what explains the expansion of the archive and the registration of those stepping stones. It's like basically a publication event in Picbreeder. It's like when I discover something in Picbreeder that I think is worth sharing, basically what I'm saying is this is interesting. I think other people might care about this and then it's out there for other people to see. That is the point of connection, the point of collaboration that actually matters. It's not like an assessment by a committee. It's just airing it to the world. Everybody can look and decide for themselves this is a stepping stone, worth our soul. So what's actually happening that's in aggregate important is the exposure of those stepping stones across society. Society is diminished in its ability to innovate when stepping stone exposure is also diminished, which is ironic if you think about it. Our committees are basically designed to diminish the exposure to stepping stones. I send my proposal to the NSF. Some committee looks at it. They say, "No." Nobody hears about it ever again. It may be out of thousands or millions of people, one person would've seen this as interesting and it would've changed that person's life. This is not the design of how our society works at all, but what you have to understand is that these connections happen this way. It's one in a million type of things that one person sees the potential. No one else sees it before that person. A committee of five people is crazy in that case. Even if they're experts in the fields, whatever, they just basically represent the status quo. You need the person that's off there on the side who can see the potential. So I think what we should be thinking about is interestingness and what it actually means.

[00:50:08] Patrick: It's crazy to think about how this impacts the world, and there are examples of this. The idea of permissionless innovation or publishing is something that I think has been really important on the internet and the cost of experimentation, which we haven't talked about seems like a key variable. 30,000 generations is cheap for a computer. It's freaking expensive for a human. What you would want is to promote low cost and fast experimentation, and all these things I think have their proponents. What do you think this means about living an interesting life? It seems as though the anxiety associated with goals, at least from my personal experience, is that you said something you want, even if it's naïve like, "I want more money," or whatever it is, "I want the perfect spouse," all the things that I think we all say we have as objectives that you're just living this state of anxiety, horrible anxiety because you don't yet have the thing you want. Whereas I think you're proposing an alternative, which is literally every day you could say, "I'm just going to compare my reference class, all my experience to the stuff I find today, optimize for novelty, try to proliferate that novelty or combine available stepping stones in interesting new ways, maybe I'm happy all the time." What do you think this means for like our lives and our happiness even larger?

[00:51:20] Ken: I think it does apply to your individual life. To me, it's fascinating because it starts with experiments in artificial intelligence that are very dry and not in personal, in any way. This is about AI, but eventually, it seems like the insights here do extend, I think, profoundly. When I think about it, we do run our individual lives this way. I did agree with you. It's toxic, psychologically toxic, which is really interesting, isn't it? It does feel like something about society, something about all these goals, percolating through life.

[00:51:51] Patrick: We're attached to them, right?

[00:51:52] Ken: Yeah. It's just stifling over time. It seems to grip you from a really early age, from six or seven years old or something. You're just in this constant objective vice and you can't get out of it. It makes you sweat. I think it must be satisfying to hear an argument against that. Why would it be personally helpful to hear this algorithmic argument? It's probably because at some level we know that this is not natural. This isn't how the world works. That's why there's cognitive dissonance, I think, in life. It's so objective like Western culture, maybe more culture than Western culture. So many objectives pervading everything. We somehow, I think, at some deep instinctual level realize this is insane. It doesn't make any sense, and it's actually true. It's insane. It's not principled, whatsoever. Again, we have to concede that in some cases you want to lose weight or something. It can make sense to have the objectives. You don't want to eliminate all objective thinking from everything. In this self-discovery or "What am I going to do with my life?" type of stuff, I think that's analogous to blue sky discovery at a society level. You're trying to discover something that's meaningful to you. That includes even love or cliche things like that. It's like it does apply to those kinds of things. How am I going to find that thing, that thing that makes me satisfied? Is it even possible? What does it even mean to be like truly satisfied for your entire life? That's very blue sky. I think the stepping stones are totally unclear. Then of course, the same principles will apply and the same uneasiness will apply because you're like, "Oh, but I have this whole plan for myself and I'm going to set an objective, and then what am I going to do? I'm going to have to be random." Again, you don't have to worry about being random again. You can look at this as we just do things that are interesting, collect those stepping stones for yourself now. Those are individual stepping stones.

You give yourself multiple opportunities and you use those as jumping off points to find what makes you satisfied, interested, rich, whatever it is that you're worried about, but there's a big caveat, which I think is very important at the individual level to acknowledge, which is that there's risk involved. Everything we've been talking about, this entire conversation involves risk, and it's very important I think when you're talking to individuals especially, but even at institutional. We have to acknowledge we're talking about taking risks. It's like having a portfolio, having a repertoire, having an archive of things. Some won't pay off, and it's very important at the individual level I think to understand. If this advice is appealing, you have to understand that what you're getting into is a system of taking risks. I mean, you're taking informed risks. So you understand the risks you're taking, but it's obviously true that if you follow a path because it's interesting, there's no guarantees of anything, whatsoever, and it could end up failing. You're doing this, hopefully, with the awareness that it might not pay off in the end and you think it's worth it. That's why you would do it. Not all interesting things turn out to work or to work out. That's why it's good to have a portfolio investment perspective, and some things will pay off, not all things. So it's good to have your own little portfolio of things you're pursuing, but even then, we should acknowledge that there's a legitimate approach to life, which is just to have modest aims, which is less risky. You should choose things for your life that make sense for you, and you're not obligated to take risks. If you do want to have a process of self-discovery or just discovery in general, do things that are really remarkable from your point of view, then you'll have to take risks. There's no choice. The whole idea of our interestingness, repertoire, stepping stones, it's all about risk. So you have to take risks in order to have amazing ends.

The Effect of Constraints on Inventiveness
[00:55:15] Patrick: The most alive I've ever felt is in these moments of creativity or discovery. I think everyone wants that. Even if they haven't had it, if they had it, they would want it from that point forward. The human ability to combine disparate parts into new combinations is the coolest thing in the world. It's driven our whole history, but it's also on a personal level, speaking from my own experience in the limited times I've combined anything and anything interesting, it's just the most alive that I've ever felt. I now wonder if you could talk a little bit about the role that constraints play in this. You and I talked about this great computer scientist, Brett Victor, and his notion of inventing on principle that rather than have an objective, you should instead focus on a means not an end that you believe deeply in. His is this one about how programmers should be connected to the output of their inputs, and you can watch a talk from him that's awesome that we'll link to. I wonder how you think about constraints. It seems as though constraints really play a key role in creative output. If we all had our own open-ended algorithm, I'll call it, of discovery that makes life worth living and make us feel so alive when we're discovering things, constraints is the last piece of this, I think, that's really important, and maybe even intentionally choosing your own constraints to live your life by. How do you think about constraints in the role that they play, even in something like evolution, which is survive and reproduce? Those are pretty powerful constraints that have led to insane outcomes.

[00:56:41] Ken: Constraints do play a role. It's very important that they play a role. If you don't have constraints, you are veering more towards randomness. Constraints are what make the collection of interesting stepping stones less random. It means that there's some principle that's still selected. The word interesting is very important, playing a big role here. It's a hard to define thing, which is intentional here because it's supposed to encompass everything that matters in life. This is very broad concept of what's interesting and it is different for you and me, but it's certainly a constrained concept. If you were a constrained, then you would archive things that are of no interest. You would be keeping around stepping stones that are basically insane and have no potential. So clearly, you have constraints, but what do these constraints mean, and what's a valid constraint? I think it's really good to point to evolution because we haven't done that yet, that evolution is an instructive example because natural evolution is an example of an open-ended process of stepping stone collection as well, an insanely powerful one, but it accounts for the emergence of all of living nature. That means every single creature that you see out your window is part of one search process, which is evolution, and there is clearly a constraint there. Actually, I should clarify. Why is it not objectively driven? People say, "Oh, but it is objective. Survival of the fittest, it's an objective." What I mean by non-objective here is that there isn't a creature that it's aiming for. The actual products, the concrete products of the process like a human, like a bird, like a plant photosynthesis, the birds represents flight, and human represents intelligence, you're going to get these all really important discoveries from a single process of discovery.

None of them are the objective. None of them are written into the rules. If you just look at try to survive, you cannot predict bird. That is just impossible. So these are not objectives in the usual sense. I think that the survive and reproduce thing is constraint. It's a strict constraint. It means that basically it's a very weird constraint if you think about it. It's not usually said this way, but basically, you can just be a walking Xerox machine. In your stomach, there's a Xerox which can make a pretty good copy of you. That's a machine inside of you, and then the copy you make also has a machine inside of it. That's a pretty tough constraint. To build something that can make a copy of itself is crazily hard. Actually, I think that's what keeps the process honest in some sense, and that's why it doesn't devolve into just a bunch of inert blobs lying on the ground because it would if that wasn't required. Basically, imagine this is a thought experiment, but if you intervened in evolution and so that everybody gets to reproduce. We're not going to have constraints. So it doesn't matter what you have. We'll make a copy of you, some entity. This is a total thought experiment, but we'll just give you a child, even though you don't even have genital organs, we'll just give you a child, make one that's a little like you. Well, the world would devolve into all kinds of inert blobs covering the earth. The constraint is basically a way of keeping things interesting. That's actually what I think is really the explanation for why evolution works. It's not that it has targets like trying to create a brain. It's got a really hard constraint that everything has to be this complex machine. I think it was a Rube Goldberg machine generator. Every time you vary the Rube Goldberg machine, which is this crazy convoluted thing that makes a copy of itself, can you imagine Rube Goldberg machine that copies its own self into another Rube Goldberg machine? They're all going to be insanely complex and insanely functional forever, but they'll vary.

They'll basically fill the space within that constraint of every possible thing you can imagine. There are going to be some interesting things in there because it's every possible way you can make a walking Xerox machine. You're going to see eventually it's going to fill the space.So it's the Rube Goldberg machine proliferation, the Rube Goldberg generator is basically the metaphor, I think. I would think of as what the constraint offers. It basically ensures that everything contains a level of complexity that keeps the potential going for the next generation of cool stuff to come out. You have to decide for yourself what that constraint is. It doesn't have to be a walking Xerox machine. I mean, that's evolution. For you, it's something else. Your constraints have to do with what you're interested in, but you have to keep it honest. If you put your standards down and you're not really keeping things interesting, then yeah, things will devolve towards the inherent blobs covering the earth. The constraints matter a lot, and they're what keep the stepping stones interesting. So the leading edge of pick breeder are things that look like stuff. They're not all, by the way. There's some things that are just really cool wallpaper pattern. So there's more to interestingness than meets the eye sometimes, but they're basically all really interesting stuff. Whatever your field is, you got to look at it from that perspective and just make sure that you understand what interesting is. I think you can. If it's a field that's your field, if you spend years and years in a field, you're qualified to understand what's interesting and that's different than having an objective. That's a constraint.

[01:01:11] Patrick: The constraint thing is so cool. Obviously, we can't prescribe them for people. They have to light on them themselves. I haven't even mentioned your interesting background where you built a business that was sold to Uber that became Uber's AI labs and then worked for open AI, and you've had this fascinating history in that world of ML and AI, which is so driven by objective outcomes that we're trying to accomplish. So it's interesting that there's been a lot of advances there just through raw compute, I think, that have driven some improvement, but how do you set this for yourself? I'm curious what your constraint is. How should we think about constraints in this world of AI when we have so much horsepower now and so much potential, but all of it seems trained on definable objectives? Where do you think this could go? If we open this up, what might happen?

[01:01:57] Ken: I think that to stay on the cutting edge of anything, it requires continually refining your sense of interestingness. It is I think for everybody, including me, a very complicated and a very exhausting process to really continually be sensitive to what's interesting because the thing is it changes over time because novelty is, of course, like you mentioned novelty, and I haven't mentioned it a lot here, but I often talk about it when I'm talking about this in the field of AI because novelty is an intrinsic aspect of interestingness. It's a very important factor in what's interesting. What is interesting is changing constantly. If you rest on your laurels and you think about what was interesting 20 years ago, and maybe you were really good at identifying those things, it's not going to be true 20 years later. That same heuristic will no longer apply because the world has moved on and that's no longer going to lead to novelty the way it did 20 years ago. I think this is why people fall off their game understandably and excusable, but it happens because it's just very tiring to keep up with really the cutting edge of interestingness, which is this ability to see where's the potential now as opposed to 20 years ago.

Of course, being young is an advantage because you're coming up to this cutting edge for the first time. Everybody has their own heuristics, but I think I try to be rebellious. I tried to repudiate what I previously thought constantly to push myself in another direction. Yeah, that in a way keeps me from just getting into a comfortable corner that gets fully exploited. It's true that if you're really smart, you can find a little corner of the search space that is currently unoccupied. So it's full of low hanging fruit and you will get into that part of the search space and you will just prune everything quickly. You'll be famous after that, and then that'll look really good and you can live out your whole life based on that, but that little encounter with that part of the search space, and that's what often people do. They just find that area and then they're just comfortable there and they basically exploit it and then it's over, but it doesn't matter because they're world famous and rich by then, and there's no need to keep moving, but if you want to keep moving, you have to leave eventually. That's now a comfort zone. It's been exploited. The long hanging fruit has been picked and now you have to go somewhere else, and that's really tough, I think, because now you're famous for that little area. You don't want to leave. For myself, I try to just rebel against my own self, basically. I try to look at it like, "Where would people predict if they were me they would go and then not go there?"

[01:04:20] Patrick: I love that. That's great.

[01:04:21] Ken: "What would the obvious thing for me to do next and then that probably what I should do?"

[01:04:25] Patrick: Don't do that.

[01:04:25] Ken: Anyway, these are all just heuristics. There's no easy answer, obviously. The truth is in the richness, not in these simple rules of thumb. I have sensitivity to millions of dimensions of things that are just unique to my personality and so do you and everybody. You have to be honest with that and loyal to that, even when it repudiates you in those directions.

[01:04:45] Patrick: If you think about that novelty is so important and that novelty ultimately is about having a big reference class, to know what's new you need to know what's not new. Therefore, it seems like the superpowers are curiosity and exploration. Is that the boiled down final conclusion of all this work that you've done that fundamentally it's curiosity and exploration that drive it all?

[01:05:07] Ken: You could say that. In some sense, that suggests, well, there's nothing new here. I would maybe add deception. It's curiosity, exploration, the idea of deception, which is when you're moving towards something and things seem to be going well, often they're not, actually. These are old ideas. It's like we know about curiosity, exploration. Everybody loves those things, and deception is not a new idea. What have we learned over here? I would say at some level what you're saying is true that, yeah, this isn't new at all, but at another level, I think what is new is just the recognition, both that there is a horrible pathology because of deception. We don't recognize how pathological deception is. It's just absolutely pathological. Also, curiosity and exploration are principled, algorithmically principled. We often think of them as indulgent suits, I think. So the new thing is they're not indulgent suits. Their principled thing to do is to follow curiosity and explore. Somehow it's like you're cheating or you're off hours or something.

[01:06:04] Patrick: Wasting time. I've gotten that one a lot, "What are you doing? You're wasting time."

[01:06:08] Ken: It's my 20% time. This is where I get to do what I really want to do or something. It's really productive. That's completely upside down. Actually, this is the principled thing to do. Now, recall, we're talking about when you're doing blue sky discovery, it's not principled if you're just trying to lose weight or drive, for example. The last thing I would want is a driver who's exploring methods of driving. That's not the stuff you want to go on the road. You don't want exploration there. So it's not like all of life we should just be curious and exploring, "Let's see what happens if I veer into another lane or something like that." That's not always good, but yeah, if you're trying to do things that involve discovery, innovation, fulfilling yourself for your life, then this is actually principled. I think that is new for most people because it's thought of as such an indulgence.

[01:06:48] Patrick: Ken, I so appreciate the work you've done. I mean, for me, it's put in stark relief. Some ideas that I've been messing with for a long time that I could never really articulate, certainly not empirically, and you've done just that. I mean, I think everyone can benefit from watching talks you've given from reading the book, from challenging themselves that in the world of objectives, if there's an existing objective, the logical stuff has been tried and probably perfected. To me, it's exciting that if I'm going to do something interesting, just again, speaking selfishly, it's probably going to result from tinkering and exploration and disparate parts and an island of misfit ideas and all these cool things. I so appreciate the ideas you put out there and also your time today. I ask everybody the same traditional closing question. What is the kindest thing that anyone's ever done for you?

[01:07:33] Ken: Well, first, let me just thank you because I really appreciate being on this show. Also, I really had a great time at Capital Camp. Such a hard question, but I think I'll just cite my friend. His name was Ed, who gave me money to do research out of his personal bank account. That's a very unusual thing. He really affected my career. Usually, people in science, at least in academia, will get money from agencies or government or from a company or something. He's not related to me or anything. He just started to give money to our research. That was just amazing, the generosity there, and he kept giving more. He was very encouraging to me, almost like a father figure. He said I was going to be a great scientist, and I was like, "Why are you doing this with your money?" He actually unfortunately died. He was 68 years old and he had cancer. I always felt extremely grateful to him for helping me get started with my career. I actually gave my son's middle name Ed or Edward to recognize him.

[01:08:29] Patrick: It's incredible, and I think demands one last question. This idea that you've referenced over and over again that no one is telling people how they have to behave in something like pick breeder. There's a permissionless nature to it. There's a individuality and individual interpretation of events. With all that in mind, for those whether it's running a grant organization or running a labs, an AI labs or innovation labs inside of a company or anyone that has resources like Ed did that want to deploy those resources in service of disruption and innovation, either generative or protecting against it or whatever, you've already talked about what they do wrong. If you were in-charge of one of those, an allocator of resources to create innovation, how would you do it?

[01:09:14] Ken: I think if you're in a position like that, you're a gatekeeper. So you are responsible for the perpetuation or not of this objective culture. It's especially relevant if you're purportedly involved in fostering innovation because that's where this gatekeeper has a huge influence. Yeah. I would recommend doing things differently. You probably exist in their framework where that's very difficult because you answer to somebody. They don't understand where you suddenly say, "Well, I'm not assessing things in this normal objective way anymore." They're like, "What the heck are you doing? How do we know this is working?" So this takes some courage, I think. The first thing I would say, get the courage because there's nothing we can do about that. You have to explain to them, "If we're not going to follow the usual security blanket rooted things, the people in the chain are going to have to be convinced and that's hard work." That's why I think it's worth having a conversation like this show. That's why we wrote the book. It's like we wanted to start people having these conversations. So get the courage to have the conversations and really fight because it's not going to happen if you don't. You're just going to shut down. You're going to think, "I want to do this, but, eh. On the other hand, my boss wants this. His boss wants that. There's a funding agency out there or we have investors." You're like, "Forget it. It's too complicated." Somehow you got to fight this.

Now, in terms of actually practical implementation, what should you do? What I would say is you should be maximizing stepping stones in the pursuit of innovation, not maximizing an objective performance. There's two things, maximizing stepping stones and maximizing exposure to stepping stones. The thing that makes innovation work is that the people who could run with something are exposed to the thing that they could run with, and that is what's missing I think from a lot of these organizations is that we have these filters, which are extremely narrow, which decide what comes through, and they end up pruning out things. It's the conversion consensus problem. Things don't get exposed to a person who would react dramatically if they were exposed to that thing. What we should do is greatly broaden the filters that go from idea to exposure to the people who could run with the ideas and then also change the criteria for what should be pursued. You have to recognize that if you pursue something that requires investment, so it costs money. So we're not talking about decisions that can be made lightly. Nobody can say, "Well, everything will pursue because now we're all going to be open-minded. We're just going to do everything everybody wants." That cannot happen. Some things have to not happen, but the way that we decide what happens, I think the criteria should be quite different.

It should not be trying to move to consensus, get a committee to agree with something, get the most vote, something like that. It should be many people within the context of the organization, whatever many means. Many people are exposed to the ideas that are being generated, and that basically only one or two need to trigger the success of that idea or to say, "This is worth investing," but then you say, "Well, how can that be?" Then every idea would have to be invested because somebody might want to invest in everything. The reason I think it can make sense is if there's skin in the game for the people who are validating the ideas. If I see something that is so exciting to me that I'm personally willing to pursue it that I didn't come up with myself, just like the alien face that led to the car in Picbreeder, then I'm actually willing to spend my time on what you did. I'm actually giving something away. I could have had that time. I could have invested in something else. What should make the confirmation of something meaningful and really worth investment is if the person who's confirming it is giving something away. Maybe they lose their right for some period of time to have their idea even considered or they give away the resources that they were giving for some project that they had. There's obviously finite resources, but if someone's willing to do that, that means that this thing means a lot to them, and it only takes one person, magic connection, electric connection to happen, and we have to somehow create those connections. It's not going to be consensus matter. It's going to be a niche thing. When there's something incredible, it's not going to be tons of people see, it's going to be one out of a hundred see it, and that has to be honored somehow. We have to find a way to do that.

[01:13:09] Patrick: What a great place to close. Ken, this has been so much fun. As always in our discussions, I learned a ton. Thank you so much for your time.

[01:13:15] Ken: Thank you.

This site uses cookies to improve your browsing experience. By using this site, you are consenting to this policy.
