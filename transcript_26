
Search our transcripts by guest or keyword
COMPANY
Careers
Blog
Shows
Sponsors
Newsletter
About Us
Sitemap
LEGAL
Disclaimer
Privacy Policy
Terms and Conditions
SOCIAL
LinkedIn
Twitter
® 2022 Colossus, LLC. All rights reserved.
Released April 11th, 2022
Invest Like the Best
Alexandr Wang - A Primer on AI
Alexandr Wang is the CEO and founder of Scale AI. We cover the building blocks behind a successful artificial intelligence business, the significant role of AI in global security, and why data is supplanting code as a company's most valuable asset.

00:00:00
01:12:25
Introduction
[00:02:09] Patrick: My guest today is Alexandr Wang, the CEO and founder of Scale AI. Alexandr founded scale in 2016, having been inspired to accelerate the development of AI through his work at Cora and his studies at MIT. Specifically Alexandr realized that there was a lack of infrastructure solutions for producing high quality data, the lifeblood for AI models. Today Scale provides data solutions to leading AI teams at Meta, Microsoft, OpenAI, Flexport, the US Air Force and many others. This time last year, the business was valued at over $7 billion. Our conversation is a primer on AI. We discuss the building blocks beneath successful artificial intelligence, AI's role in both the public and private sector, and why data is the new code. We also cover the similarities and differences between AI and software from an investing perspective and what inspiration Scale takes from AWS. Please enjoy my great discussion with Alexandr Wang.

The Role of AI in Global Conflict and Diplomacy
[00:03:04] Patrick: So Alex, we're going to talk about every dimension I think of AI, artificial intelligence, machine learning, all the things that it's going to impact. I'd like to structure our conversation from sort of the widest angle down to the most specific, which will probably be around your specific business and product. But given what's going on in the world today, I think it's probably an appropriate place to start with the role that AI data, machine learning, et cetera, play in geopolitics and foreign policy. We're sitting here in the US and everyone's mind is on Ukraine. I think everyone understands that cyber is a sort of plane of conflict that exists, but we don't know a whole lot about to be honest, even, I don't know a whole lot about. So I'd love you to give us your overview given you've got a sort of insider view and seat and understanding of all this. What role does AI play in the global theater today in your view?

[00:03:52] Alexandr: A few assumptions to talk through, a few things to talk through that I think are really relevant here. I think one is that generally speaking, deterrence has been a incredibly positive thing for world peace and the stable world order over the course of the past 40, 50 years. I grew up in Los Alamo, New Mexico, which is the birthplace of the atomic bomb. The deterrence from the atomic bomb has been an incredible function for a stable and peaceful world order. And I think where we're at today in a broad sense is that there's an entirely new set of technologies that are either in early development, being developed right now, or have been recently been developed that are significantly shifting what conflict looks like in general. One of these is cyber security which you mentioned, which is a very challenging general attack plane because it's generally speaking, almost impossible to defend against, and the attacks are numerous in nature. There's sort of like these shots that can produce a lot of attack vectors. I think AI and machine learning is a very, very significant one. Its ability to intersect with many of these attack planes, whether that is intelligence and understanding what's happening in these various theaters, whether it's through the actual warfare component or it's through cybersecurity, a cross sectional technology across each of these different fronts.

One general thing that is important to think about is that versus the prior paradigm of conflict where a lot of conflict would happen in literal physical conflict in wars in theaters, I think we're moving much more to a paradigm where hopefully 90% of conflicts are actually resolved or battled in a purely digital context long before an actual conflict arises. And so this broad shift, which is, I think is much more than just AI and machine learning, but this broad shift of sort of the physical battleground to a primarily digital battleground is probably the greatest macro shift. And then on a micro level, the ability to have great AI technology is probably one of the greatest enablers or the greatest power contributors in terms of which countries are going to able to be defend the most effectively, as well as to enable the greatest level of deterrence, the broad world order. That's the most practical view from the conflict perspective.

And then I think from a geopolitical plane, I think that we're entering this period of what's called great power competition or strategic competition, where there is a small set of highly technically capable countries who are great power competitors that are strategic competitors on a number of fronts from economic competition to ideological competition, to obviously a lot of on the field competitions. And so this shift from the paradigm of the past 20 years being counter-terrorism, this shift from counter-terrorism to great power competition means that the technology itself and in particular being exceptionally good at technology is really, really critical. Artificial intelligence is just one of those technologies that happens to have compounding order of magnitude effect on any of the other technologies that we could possibly develop. And so that I think contextualizes why all this stuff matters. And I think that something that I think is incredibly important because the way that these world events happen, and I think the Russia Ukraine conflict is one great example of this is, is that they do not happen in predictable ways. There's not a predictable logical way in which events will play out over time. It is one of these great tail risks so to speak to the good and wellbeing of humanity.

[00:07:21] Patrick: If we think about the analogs between physical kinetic conflict, culminating in nuclear deterrence, it's hard to imagine something more powerful than whatever the largest strategic nuclear weapon is against the city or something. Is something similar being developed in the digital sphere. And what pops to mind is the worry that another country or another power reaches some sort of level of general artificial intelligence to use the common term first. And that thing represents the equivalent of being the first and only to have nukes. And maybe it's even harder to copy than a nuclear weapon might be. If we are shifting to digital, what do you think the arms race equivalent is towards, what is the end state that the different powers might be trying to achieve in that digital realm?

[00:08:04] Alexandr: First of all, generally speaking for artificial intelligence, it's a very multifaceted technology. It's more similar, you would say to software or the internet than it is to like any specific technology that will be built, a very particular weapon or whatnot. And so I don't quite fully agree with this analogy that an AGI is the equivalent end state to a nuclear weapon. That being said, I do think that AI and AGI, the best way to think about is it enables maybe 10X better strategic decision making and 10X better ability to actually take action against various tactics that you want to enact. Maybe the best analogy is like playing chess versus a human versus playing chess versus an incredibly talented algorithm or incredibly talented computer. The way in which it'll play out strategically dominant behavior in extended periods of conflict or extended periods of time.

[00:08:54] Patrick: How would you describe based on what you know, the current state of things amongst these great powers, what's the status of the United States, I guess is the first question. How does that relate to the status or digital capabilities of other countries, and how does public versus private sector look? Is the US private sector far better equipped than the public sector or something like this? What's the state of things?

[00:09:14] Alexandr: I'll talk about AI technology, which is the area that I understand the best. So fundamentally AI technology, modern, deep learning was initially developed primarily in the private sector through a lot of incredible research that was done at Google and DeepMind and OpenAI and Facebook and these incredible firms, as well as a lot of contemporary research done in China, the clear other major location where a lot of great artificial intelligence research has been done. And a lot of that research there's been this very fast integration of that into very particular use cases in China. Facial recognition technology, I think is one of the primary examples where this company's like SenseTime, Face++, et cetera, that are primarily contractors of the Chinese government have built world class computer vision algorithms for facial recognition for use by the Chinese government in furthering a bunch of national objectives that they have. We may have questions from humanitarian perspective, like the work being done with the Uyghurs. That all has happened in China. Then at the same time, I think this is starting to change now, but over the past, call it five years in the United States, there's been this very unclear relationship between the private sector and the public sector or the private sector and the government around the use of AI for applications like defense and intelligence.

The Google cloud project Maven conflict was probably the most visible, most clear example of this. But as a general rule, I think that there's not the same level of partnership between the best and class technologists in the United States, as well as the government. That is a significant cultural problem that needs to be solved in the United States for us to really be well positioned in the future with respect to artificial intelligence. I think broadly speaking, we're in the very early days with all this technology, the speed of innovation in artificial intelligence incredibly, incredibly fast. I think what we do over the next five years or do over the next 10 years is probably 10X as important as what was done over the past five years, just given the pace and acceleration of the technology of artificial intelligence. I think the real question for policy makers in the United States, global leaders for technologists United States is what are we going to do over the next five to 10 years? And how does that compare to what other great power competitors will do over the next five to 10 years? And that I think is what will really set the stage for the next phase of this great power competition.

Talent as a Building Block for Scaling AI
[00:11:33] Patrick: In the world of software you always hear about these 10X engineers and one wonders if in this realm it's even greater than that. Is the talent at the tippy top of this world going to be accessible to great powers in governments like how ... This is so important and there's this multiplier effect of like the absolute best talent. Seems like that's the thing that matters, competition for that talent, not just between great powers, but also between the top engineer, AI person at Facebook versus going to work for the NSA or something. What's been your sense of the flow of talent and the importance of talent? Do I have this roughly right that it's even more important that it might have been in software?

[00:12:11] Alexandr: There's three critical component to broad scaling of artificial intelligence. One is certainly talent, which I'll get you in a second. The second is compute and computational power, which is impossible to ignore. Especially as we think about a lot of potential disruptions to the supply chain of large data centers or large shipping manufacturing, that's a really important one for us to consider. Then the last one is data and data scale. That is obviously near and dear to my heart just running Scale, but is also something I think is also impossible to ignore. So I think those are generally speaking the three vectors that matter. I mean, there's been a bunch of research that shows that more or less power of these AI systems, both quantitatively and qualitatively scales on these three dimensions. Then if you think about talent in particular, the interesting thing is there probably is a greater scaling effect, but not because the technology itself is one that is more inclined for a brilliant mind than software per se, but actually it's probably much more a function of the power law impact of various AI systems that is actually even greater than that of software systems.

I think that a lot of software systems, because they have to operate within fixed paradigms, they have more capped total impact or total utility that they can deliver. These AI systems, you think about the large language models that have been developed recently by OpenAI and Google and others. Those algorithms have an incredible ability to adapt to new domains, the cap on the level of impact or the cap on the amount of utility to be delivered is much, much higher. What that means is that the set of people who can develop these technologies, OpenAI, I don't know what the latest count is, but I think their total head count is 250 people as a corporate. That's an incredibly small number of people to generate the broad scaled impact that I think they will deliver over a multi decade time frame. So I think that's a very accurate point. This is one of the things that I think by the way, matters a lot is high skilled immigration into the United States. America's an amazing place, and I think that one of the things that is differentiated about America is a lot of people want to move to America and want to do their lives, work in America, they want to build families in America. And I think we need to do everything we can hand to enable and encourage that as much as possible. If you think about inputs or you think about the big needle movers that are actually maybe easy to change, this is one of the ones that has again, multi decade consequences.

[00:14:29] Patrick: I couldn't agree more on that point, maddening that we don't become just the perfect beacon for all the most talented people. The interesting analogy that I've heard before just to wrap our minds around the sorts of things or tasks or functions or whatever that constantly improving AI/ML models can accomplish. One model that was funny and interesting was like anything that an intern could do for you, you might be able to scale up through one of these models. It's complicated enough that a person's on it now but it's simple enough that you give it to an intern it's sort of repetitive. I always kind of like that conception. What's your way of thinking about how to communicate to your audience, other businesses using your tooling and just people general, what categories of things AI can do well, and maybe what categories of things we're excited about but might be a very long time until AI can do well.

[00:15:19] Alexandr: I think this is one of the general misconceptions about AI and machine learning, which I think causes a great deal of FUD. Which is that the intuitive belief is that the things that are easy for humans to do are going to be the things that are easy for AI and machine learning to do, which is absolutely not the case and the things that are easy for algorithms are relatively orthogonal, frankly, to things that are easy for humans to do. One simple example here is I think that it's going to be a very, very long time before we have home robots that can do things like fold your laundry and your dishes, but a much shorter time span/I think this is already today where you can have artificial intelligence systems that are world class copywriters and can write better rhetoric, better words than most people ever could. There's probably a few frameworks I would assign to this. I think in a broad general sense, one way to think about the potential impact or lower bound potential impact of artificial intelligence is kind of as you mentioned, which is the ability to scale repetitive human tasks. So take repetitive human tasks instead of going from zero to one, go from one to N human work. And I think that this is a generally amazing thing to happen because I think that humans for the most part don't enjoy repetitive tasks or generally find those relatively unpleasant and find it much more exciting to be creative and to constantly be creating.

This ability to scale human tasks from one to N, is going to be this incredible, not only economic good or economic enabler for the world, but also going to be a significant enabler for humans to be more leveraged, more happy, more creative, et cetera. I think that's one way to sort of contextualize the broad impact that AI can have. And there's a bunch of other nuances, which I'm sure we'll get to. If you think about what tasks humans are good at versus what tasks algorithms are good at, generally that more or less boils down to data availability, which is that where there are large pools of digital data an algorithm can learn from, and those pools of digital data either have been collected in the past or easy to collect in the future. Those are going to be the problems which algorithms can do effectively and can learn to do effectively. And then areas where there does not exist digital data and is expensive to collect this digital data. Those are going to be the last things to be automated. So a great example is if you look at GPT 3 and these large language models, the real secret behind it is that it leverages two decades of Reddit data, which is two decades of humans using the internet and basically typing language into the internet in various forms for decades and decades and decades. And that is a pool of digital data that it used to be able to do these incredible things in writing long form text.

Then if you think about this parallel that I mentioned around home robot, there's so little data about actual capture data of let's someone folding a shirt, or somebody folding a towel, or going around and doing chores, the ability to actually collect and produce that level of digital data necessary to produce algorithms that can understand that and actually perform this task is an incredibly, incredibly, incredibly hard road. This extends by the way to things that are really unintuitive. So for example, DeepMind and OpenAI very recently released algorithms some of which are very good at ... DeepMind released an algorithm that's very good at competitive programming, OpenAI released an algorithm that can prove very difficult math problems or math theorems. And these are both things which are very, very challenging for humans to do. Very, very premium skill sets as far as humans go. But there are incredible pools of visual data as well as abilities to verify or simulate the outcomes here, which allow these algorithms to reform actually incredibly, incredibly well. There's this very interesting process by which artificial intelligence will slowly automate or meaningfully change what human jobs that are primarily digital in context will look like. And then a lot of the physical work will I think be generally on touch for a very long time.

[00:19:11] Patrick: In many ways, if you're right, the whole idea of blue collar work let's call it or something like that being in jeopardy is maybe completely wrong. That the white collar work, that sort of knowledge work that's mostly digital in its form today is more susceptible. As you said, this should be a good thing, right? It should open up human leverage to higher order, more creative, more interesting tasks, non-repetitive tasks. I think that as of this morning, jobless claims are at their like all time low or since the 1960s or something. So all this great technology doesn't seem to have affected things that badly, but is that right that some of the jobs that we thought might be automated first by robots or something actually might be the last things to get automated by this model. And the more knowledge work stuff may be first?

[00:19:54] Alexandr: It's a strange thing, but I think that probably is the case. Maybe one simple model is if you spend all day in a Word Processor, all day in Excel, the actions that you take in those products are some of the most likely to be automated, frankly. And for the most part, I think a lot of that work is probably not very inspiring and so it will be this incredible enabler of leverage to think bigger about those kinds of jobs.

Principles for Creating and Using AI Models
[00:20:18] Patrick: Maybe it makes sense to help people understand the process of creating one of these models in the first place. I think the discreet steps, let's say the outcome is a model that makes a useful prediction. Ultimately, this is all predictions instead of what's being generated by the models in the first place. I don't know where to start, whether it's with raw data or annotation of data, and we're starting to get into what Scale now provides for companies. But how do you think about explaining the discreet or the important stages of building one of these models in the first place? I think just understanding that architecture will let us dig into each piece a little bit more.

[00:20:51] Alexandr: Again, everything starts with the data. I often will analogize the data for these algorithms as the ingredients that you would make a dish with, or the ingredients that you would make something that you'd eat with. Is incredibly, incredibly important. We often say this thing, which is data is the new code. If you compare traditional software versus AI software, in traditional software, the lifeblood is really the code. That's the thing that informs the system what to do. In artificial intelligence and machine learning, the lifeblood is really the data. That is certainly like one major change. That's really important. The life cycle for most of these algorithms is a few fold. So first is this process of collecting large amounts of data. By collecting it could be data that is already sitting there. There's a lot of software processes that already collect a bunch of data. There's a lot of cameras in the world that already collect a bunch of data, but you need to get the raw data in the first place. Then it goes through this process of annotation, which is the conversion of this large pools of unstructured data to structured data that algorithms can actually learn from. This could be for example, in imagery or video from a self-driving car marking where the cars and pedestrians and signs and road markings, and bicyclists and whatnot are so that an algorithm can actually learn from those things. It could be for example, in large snippets of text, actually summarizing that text so that now we can understand and learn what it means to actually summarize text. So whatever that translation is from unstructured data to a structured format that these algorithms can learn from, then it goes through a training process.

So these algorithms basically look through these rims and rims of data, learn patterns and slowly train themselves so to speak, to be able to do whatever task is necessary on top of the data. And then you launch one of these algorithms in production and you run them on real world data, and they're constantly producing as you mentioned these predictions. The very important piece is, this is not a sort of like one way process this is actually a loop. If you look at almost every algorithm that has launched out their own production, it is not a sort of you build the algorithm and then you're done because these algorithms are generally very brittle and unless you're constantly updating them and maintaining them, they will eventually do things that you don't want them to do, or they'll eventually perform poorly. There's this critical process by which you are constantly then replenishing them. You're constantly going and recollecting new data, annotating it, training the algorithm, launching that new algorithm onto production and you constantly undergo this process to create very high quality algorithms.

[00:23:19] Patrick: I want to make sure that this interesting point you made about data being the new code really hits home for people, and maybe even put that in a business context. So if the IP or the moat of a software company is this code base that takes a very long time to develop, has all sorts of dimensions to it. Maybe it's microservices, maybe it's some code monolith, it's questionably like an incredibly valuable asset. It's digital, but it's an incredibly valuable asset to the company. And you're talking about, I think, a transition where it's something different where maybe, I don't know, maybe Google's data repository or something, is this unbelievable advantage that they have because no one else has access to all of their data. Is that kind of what you mean? That ultimately maybe something like Google, their data is worth a lot more than their code base. And that that would become a trend that we see sort of across industries?

[00:24:07] Alexandr: If you look at the highest performing algorithms across a variety of different domains, image recognition and speech recognition and summarizing texts and answering questions of texts. So these very different cognitive tasks, look under the hood, they actually all use the exact same code base. That's been this very meaningful shift that's happened over the past few years in artificial intelligence. We're at this point where the code has become effectively the same and more or less a commodity so to speak when it comes to artificial intelligence and machine learning. The thing that enables the differentiation is really the data and the data sets that are used to power these algorithms. To your point, if you think about ... One of the ways that we talk about this in a business context is if you think about what is your strategic asset? In general in business, your strategic assets are the things that allow you to differentiate yourself against your competition. In a world where 99.99% of the software in the world is sort of traditional software, and then only 0.01% is AI software, then you care the most about your code. Your code is what will differentiate your product versus your competitor's product or your processes versus your competitors' processes, et cetera. But then as more and more of the software in the world's written, infused with AI, using AI or over time the interfaces shift to AI. Interfaces and Alexa like interface for example, as that shift happens, as you go from 99.99 to 90:10 or 80:20, or even 50:50 over time, the vector of differentiation totally shifts to data and the data sets that you have access to. And so that means is that your strategic differentiator to your point as a firm is going to be primarily based off of what are my existing data assets.

And then what is the engine by which I'm constantly producing new insightful differential data to power these core algorithms that are actually powering my business. And these algorithms at the core that will power the future of business, I think are relatively core. I think there's definitely algorithms around automating business processes that are going to result in significantly more profitable firms over time. There's going to be algorithms that are based around customer recommendations and customer life cycle, which is a lot of the algorithms that we've seen date. Imagine TikTok recommendation algorithm, but for like every economic interaction or every economic transaction in your life that is constantly identifying the perfect next thing that you may want to transact with. And that is going to exist across every firm or every industry is basically going have to build their version of that. And that's going to result in significantly more efficient trade. The long-term impacts of that you could think of as like a general reduction in marketing expenses or sales and marketing expenses because the algorithm just does a better job at knowing what the user wants to do next and having to do all this marketing and all this very active sales. There's a lot of very real changes to I think the physics of what the best businesses will look like in, let's say a decade or two decades or three decades that come from artificial intelligence. If you think about what will allow me to do these things better than someone else, it's the quality, efficacy and volume of the data that is used to power these algorithms.

[00:27:16] Patrick: If getting to that state of some sort of differentiated data advantage is the goal, then that engine that you referenced becomes critical idea for any company, a piece of infrastructure. What principles are there about building a good engine for data gathering, that maybe cut across different types that you've observed. What's behind the great engines that you've seen for gathering data?

[00:27:38] Alexandr: There's a few tenants. I think first quantity is a quality of its own. You want to just have lots and lot to data coming in. That will be a differentiator, no matter what, not all data is created equal. And so you want in general, the way these algorithms work is it's sort of like needles in the haystack, almost in most of your data that end up being differential valuable. You'll want to develop a process by which you can actually what's called curate, but identify and understand what are the really valuable pieces of data in general data inflow that we're getting. You'll want strategy for data diversity, or you'll want a strategy by which you're not just going to keep collecting the same old data by which you're going to constantly be expanding the domains or the kinds of data or the diversity of data that you're going to be collecting over time. That's a really interesting one. I think that one of the more intuitive examples that I think people understand the best is that Tesla's autonomous vehicle strategy. One core part of their strategies that they have all of the Teslas in the world are in some sense collection vehicles, they're all encountering very rare situations that then improve and help the machine learning algorithm. There is a truth to that idea, which is that because not only have a greater volume, but they also have great systems who identify these needles in haystack. That's a strategy by obtaining an incredibly diverse data set over time, that's very beneficial to the long term differentiation of their machine learning stack. By the way, Tesla has other challenges as well. So this is on a clearly dominant strategy, but there is truth to some of these ideas.

[00:29:03] Patrick: What should we know about the state of technology around annotating data that I know obviously Scale is deeply involved with the example in Ukraine around like satellite imagery. There's this interesting jump from like raw data or raw input into some sort of refined signal or piece of information or whatever. I don't know what the right terminology is. What is the state of that in the world today? Has that changed a lot? Has that been pretty constant over the last few years? Where's it going?

[00:29:30] Alexandr: I think it's meaningfully changed. It's one of these very interesting problem domains and one that we find incredibly exciting because it's undeniably a "dirty problem," or it's undeniably a very complex multifaceted, operational and challenging problem. Historically speaking, this has been done in an incredibly low tech way and an incredibly very manually intensive way for the AI industry to date. And a lot of that has been because it hasn't been a problem that technologists have wanted to dedicate themselves to. For the most part, most people who go into computer science or most people who go into artificial intelligence by definition, they go into computer science because it's a significantly more constrained problem that doesn't involve these complexities around human operations. But I'm proud of the Scale team for having really done a lot of this work that I think will be seminal is starting with a very manually intensive or manually challenging process that is operationally very intensive and then adding meaningful amounts of automation, whether that's algorithms that will do a lot of the work before it gets to people, or algorithms are able to identify most of the errors that people might make, or in general, injecting a lot of operational efficiency processing into this process to enable significantly better outcomes and either more efficient processes or more higher quality data.

That is really the core engine behind what we've built at Scale that has enabled some of the biggest platforms in the world, such as Meta or Microsoft, or many of these other large tech firms to significantly scale out of their machine learning efforts. One of the companies that we really look to for inspiration and we've been deeply inspired by is what Amazon has done in two different spots in their business. They've done it not only with logistics for eCommerce, but they've also done it with AWS. They've taken both of these very large complex half operational half technological problems, and they've added significant amounts of technology and automation and operational efficacy to result in orders of magnitude better performance than you could have accomplished in the past without sort of this embrace of the messiness of the problem.

Building the AWS of the Future
[00:31:31] Patrick: A good excuse to talk about literally what Scale does more than an hour in. And it got into the business itself, a whole bunch of amazing context and lessons so far. What are the building blocks? I'm struck that if you go to the little products tab on Scale's website, it looks not dissimilar from the AWS tabs of old where there's lots of individual functions that are part of this value chain if you will, of building one of these things that you can "hire" Scale to do. Just talk us through the business itself, what it does for customers and how that product lineup fits together. If you are the retail operation infrastructure equivalent or the AWS equivalent for the AI future, what does that look like today?

[00:32:11] Alexandr: Where we started was really this problem around data annotation, because what we noticed is that it was this massive bottleneck for the overall progress of machine learning is that most firms could simply not get high enough quality data sets for them to actually build great algorithms. Those very much the initial problem that we set out to solve, which is how do we enable companies to get better data to fuel better AI at its core. And we started by doing that with some of the most technologically sophisticated firms in the world. We work with, as I mentioned Meta, Microsoft, we work with large automakers and building autonomous vehicles like Toyota and General Motors. We work with OpenAI on a lot of their cutting edge research, work with large internet companies like Instacart or Etsy or Flexport on a large scale machine learning problems. And then through doing that, we've built what we really believe to be the best engine in the business or the best engine in the industry around producing these very high quality data sets.

And a lot of our view in expanding beyond that has been that primitive is incredibly powerful and then integrating that primitive with other components of broader machine learning life cycle that was referencing before enables us to produce really powerful products, just like how for AWS, they started with the primitives of storage and compute, and then they sort of combined those primitives in many interesting ways to produce these incredibly powerful products like RDS or their DNS products or the list kind of goes on and on, to solve customer business problems. Really look at the same way. We have built this core primitive around data annotation and the production of high quality artificial intelligence data sets. We can combine that with other primitives that we've built such as data management products, or model monitoring products or algorithmic development products. And we combine all these primitives in producing these products that solve really core customer problems, whether that's in the government space, working with defense and intelligence agencies and building really high quality artificial intelligence algorithms to solve core national security problems, or that's in solving, working with large complex fortune 500s who have incredible amounts of unstructured data, such as documents flowing into their business.

And we build automation to support a lot of that document processing, or we work with large math builders and we use artificial intelligence and human processing to enable this map creation. One of the great lessons from Amazon as a business is that parallel execution is incredibly powerful. The traditional business logic or the traditional business truism is around, "Hey, you should really just focus on a few things and do those things really, really well. And that's your sort of like strategic edge." Amazon really threw that out and became very focused on parallel execution while focusing on what are the primitives that are going to enable them to build a lot of products very successfully. And we take more of that approach, which is we've built incredible primitives. We're going to make those primitives better and better and better. And then we're combining these primitives into building best in class products for our customers.

[00:35:08] Patrick: One of the things you'll hear about Amazon Web Services specifically is that at the end of the day, what they're really trying to drive people towards is more S3 and EC2 storage and compute spend. Those are like the most basic building blocks and a lot of the other services that AWS provides effectively maps back on to increasing the volume of storage and compute as a business model. Do you think that that's true for you all too? And if so, what are the S3 and EC2 equivalents for Scale?

[00:35:35] Alexandr: We think that's true to an extent in that, again, we're almost religious in this belief that better data results in better AI and the data is a new code. And so we really think about as like, how does Scale become the long term infrastructure provider to powering more or less the global expansion data to meet the needs of AI globally? That I think is certainly one very large driving factor and a lot of our goal is to build the most data centric, AI infrastructure platform out there. But at the same time, I think that maybe one of the things that we really index on as a company, and I think that some Silicon Valley companies do this some don't, but we would certainly take this approach is to really index on the customer value creation, which I think is really important in the space of artificial intelligence and machine learning because frankly speaking, this has been a technology that people have been talking about for a very long time.

And then the actual value creating use cases are few and far between. There's a lot of distrust of AI systems. There's a lot of belief AI isn't good or AI is so bad or AI is just this snake oil technology. That is absolutely not true. Artificial intelligence is incredibly power technology, but there's been an incredible dearth of firms that are focused on how do you index against the actual customer value and the customer outcomes they're able to generate using technologies. On the one hand, we probably do believe this large scale growth of the primitive belief around large scale growth of powering these data sets for machine learning. We also believe on the other end of working very hard to power as big or as meaningful customer outcomes as possible. And that being a primary metric fund which we value ourselves.

[00:37:08] Patrick: If we zoom in on the original use case helpful annotation of data, what does that mean in the literal sense? If the outcome is well labeled, clean, large data set, and the input is whatever, what is the gap that Scale was filling? What is the function that it was actually doing to help the company produce more cleaner, better data?

[00:37:31] Alexandr: This is sort of the state of the market that we saw when we entered it. Even when we had started, there were large number of very talented machine learning teams that were solving varied problems from autonomous vehicles to building AI for eCommerce to building sort of voices and systems. There were a lot of interesting use cases in the technology. Each time we'd go to one of these firms, we would ask them, what are your biggest problems, always in the top three data quality and data volumes, one of them, and you'd dig into it. And it's because they have this incredible challenge of motivating their incredibly brilliant smart ML engineers and ML scientists, and working on journey problems around data and data quality. So these gaps are technological. Sometimes these gaps are cultural. I think for us, we really view as some mix of both. But what we did is we went into all these firms. We took incredible religion and care to build great technology to solve data quality, data volume, bottleneck. Those really limiting the efficacy and power of their machine learning models at the end of the day, and sort of rebuilt. We took, I don't know, maybe to stripe the playbook is what you would say it was with the AWS playbook before them. We built great developer APIs and a great developer platform that enabled the machine learning engineers and machine learning scientists to basically hid an API, get as much high quality data as they needed, or they wanted. And behind the scenes, we would do an incredible amount of dirty work to make this possible and actually enable them to build these great algorithms.

[00:38:54] Patrick: Maybe just to nail the point home, like a couple examples of these dirty jobs might be the categorization of images or sub components of an image or something like that. Would that be like a good example?

[00:39:03] Alexandr: Yeah. Great examples are like given a huge amount of imagery or a huge amount of data off of a robot, whether that's a software in car or some other robot marking and all that imagery, what are the things that are important for that robot to see? So enabling the robots to see in the first place, other similar "dirty jobs" are for financial services firms. They have incredible amounts of transaction data. All this transaction is fundamentally unstructured. So understanding who are the vendors in these transactions, what are the locations? What are the other pieces of insight that you can pull out of these transactions, and other ones around other forms of audio data. For example, and pulling out the relevant intent and understanding from audio data. So all these dirty jobs, they fundamentally start with some data format that machines can't read today and making them effectively legible for these machine systems.

[00:39:52] Patrick: If I fast forward and think about Scale's future 5, 10 years down line, how would you describe the absolute best case of success? So if the mission is accelerate the development of AI, make it easy for companies to build more AI models effectively, which I think is kind of the core mission of the firm. What is the best version of that look like do you think 5 or 10 years from now?

[00:40:13] Alexandr: I mean, I think we really take the view that it just comes down to the customer outcomes that we're enabling. So rather than thinking about what Scale exactly looks like in 10 years, I think the right thing to look at is in 10 years are the majority of companies in the world able to effectively use artificial intelligence in some very high impact application to solve a business need. Is that application in some way or another powered through Scale products? And we take a very open minded view is we're going to build lots of products over time that can power these products in different ways. The delivery mechanism of the algorithm, we may not build the exact product that a fortune 500 uses. We may be powering some SaaS company that is integrating AI into their product that the fortune 500 uses. We basically want to take this very long term platform view that as long as we are there powering decade long massive expansion of AI and machine learning, we're going to be really pleased and happy.

[00:41:11] Patrick: If we zoom out and go to the more market side of things and put my investor hat on and think about what drives enterprise value, value creation, the things that investors ultimately care about when they're putting money into a business, they want to get a lot more money out. The world of software has obviously been a center stage for seven, 10 years now because they've tended to be very scalable, fairly high margin, incredibly fast growing businesses. And the word that you never want to hear as an investor is deceleration, in the growth world where maybe they're reaching saturation points and software is no longer a new thing. It's a fairly mature thing. How do you think about, you mentioned this concept of thinking about like an S curve and maybe we're for software approaching the diminishing part of that S curve. Where is AI in that same thing and how might these two things intersect to form lots of new enterprise value in the future if software becomes overly saturated?

[00:42:04] Alexandr: One thing to think about software for a moment, the sort of alchemy or the magic of software is that A, you're able to collect very large scale data sets in a very coordinated way, B that you're able to build simple workflow tooling on top of these data sets, think about your traditional CRM or frankly the majority of SaaS tooling is workflows on top of these data sets that enable business value. Then three is basically infinite scalability of a lot of these systems. These are some of the like technological primitives that have enabled SaaS broadly speaking, or software in general to produce a lot of value for most enterprises, but these primitives or these forms of alchemy have some cap, that's for the saturation of software that you're mentioning. Well, then if you think about AI technology and you use this mental model that I mentioned before, which is the fundamental promise of AI technology is you can take repetitive task that people are doing, you go from one to N with those repetitive tasks so you can automate the Nth repetitive tasks rather than relying on humans for that. Well, if you look at the majority of fortune 500 businesses or the majority largest enterprise in the world, there are an incredible number of parts of their business, where they spend enormous amounts of money on large teams of people to do repetitive tasks.

The alchemy that is possible there is not only the automation of meaningful parts of that work, but also the ability to even go further than even the best trained humans could do in many of those tasks. There's some value that potential economic value or the TAM so to speak of AI machine learning is just absolutely astronomical. I think that is at minimum 10X, probably 100X the total business value that has been generated by SaaS systems or software historically, I think if you think about it, you have this one S curve of the saturation of software. And then there's this very, very early S curve that is being developing right now around the productization and productionization of large scale AI systems, let's say in the enterprise, or let's say across businesses. And the real question is, okay, what's the pacing of that S-curve versus the pacing of the saturation and deceleration of the current software S-curve? And I'm an optimist in not too long, we're going to have a massive proliferation of AI use cases within the enterprise that are going to be way more impactful than the use cases of software in the past. And the way you'll see that the business ROIs generated from high quality AI systems are going to be 10X more than the business value generated by let's say, deploying a CRM or deploying an ERP system.

[00:44:33] Patrick: How would you advise those listening who maybe run businesses and are nodding their heads and think this all makes sense. This is a new competitive plane or competitive frontier. And I want to make sure I'm not left behind, but I'm not a data scientist. I don't have this in my background strategically or tactically. What would be the questions that you would have them ask themselves to start incorporating this thinking into their business?

[00:44:57] Alexandr: I think the big questions are really around understanding the data that powers your business, and understanding at a meaningful level what are these potential data sets within your business that can fuel a lot of this future way of artificial intelligence and machine learning. Then I think it's really thinking about, and I think this is probably in partnership with partner or in partnership with advisors, is thinking through what are the highest value business problems that artificial intelligence could solve that would meaningfully move physics of my business. I kind of mentioned a few of them, but one that I think applies to nearly every business is problem around customer recommendations or basically building better recommendations to empower customer life cycles. Another one that I think empowers almost every business is taking some of the most expensive, repetitive process internally and figuring out ways to automate or make those more efficient.

And I think it's thinking through what are these core business use cases. One very tactical piece of advice that I'd give is one of the challenges of AI is we're going to have this huge shortage of human capital that is trained in AI and machine learning and deep learning for a very long time. I think that's going to be big bottleneck for many decades, frankly. I think for most business owners, you identify partners who have some of that human capital and have a lot of expertise and experience to help guide you through that process. Whether that's Scale or whether that's another company, it is important to identify these business partners who can help accelerate journeys here.

Potential Risks and Implications of AI
[00:46:24] Patrick: I love the human capital angle. I mean, we're still short traditional software developers and engineers, and we're into that cycle a long way. So can imagine this is that on steroids. What, if anything worries you about the proliferation of all of this technology, maybe even the technology that you yourselves are developing that allows faster development of AI models? I'm of the view always that technology is sort of like a morally neutral, it can be used for good or bad. I like to think that it's mostly used for good it seems that way, based on outcomes over time, but what is concerning to you about the potential or the leverage that this might give people that shouldn't have it?

[00:47:02] Alexandr: One major one that actually keeps me up at night is this thing that we talked about at the very beginning, which is AI in the context of geopolitics and great power competition. I think that there is an incredible potential for AI to either rapidly accelerate or result in bad outcomes for some of the conflicts for the next call it 50 years. And so I think that is one very pointed, specific use case as the terminology that does keep me up at night. In addition to that, I think there's these two competing curves in AI. It's interesting to see how they'll play out, but one of the things that I think generally technology, concern about any sort of technology accelerating is inequality in the world. I think that it's not totally clear with AI, what the exact effect is, intrinsically the technology benefits from scale, the bigger and bigger models are, the better and better it is that results in new building better AI systems. Generally technologies that favor scale do result in greater levels of inequality. I think that's something that we really need to watch out for. At the same time that's why the democratization of the technology matters a lot. And that's also why the building it into use cases that affect a lot of people and enable a lot of people to who live better lives is also really critical. Again, there's sort of these two competing curves in the technology. One is the benefits to scale and the other is lowering of fixed costs and the democratization of the technology. And I think we would need to be very mindful about how these curves intersect over time or what the directions look like and the relative speeds.

[00:48:27] Patrick: What is the most interesting AI model you've ever seen?

[00:48:31] Alexandr: I'll nerd out a little bit here. I'm preposition to like these scientific applications, but both alpha code and alpha fold are deeply interesting machine learning algorithms. I think that alpha code is almost like brain break in terms of thinking that you have these machine learning systems, they can solve these competitive programming problems better than the median competitor, and the competitors who compete in these things are already incredibly high up on the distribution of humans who can do some of this work. Beating the competitors is probably beating 99.9% of humans at these programming tasks. And that's just insane. If you had asked me even five years ago, if I thought that was going to be possible, I would've said no. I don't think that AI systems are going to be able to reason and think through these complex creative problems well enough, but here we are, again, the availability of the digital data. We have systems that can perform that well.

[00:49:23] Patrick: What's an example of that? What would be something that alpha code is producing that a very talented human competitor is also producing so we can compare them.

[00:49:31] Alexandr: There's these classic programming questions, almost like the interview questions that a software engineer would be asked in an interview process. So classic brain teasery algorithm questions that for decades we have used in Silicon Valley to test incoming engineers for their talent. That's something that the machine learning system alpha code can perform just as well as some of the best engineers out there. So another way to look at this, if your touring test is a set of programming interviews to get a job at Google, you probably have a machine learning system now that can pass that touring test. It's a pretty shocking thing and I think that this is more philosophical, but I think that myself as a programmer, I think a lot of programmers take pride in their role as sort of the master of the machine, so to speak, or the person who tells the machine what to do and programs the machine, it's this funny role reversal that the machines are now better at a lot of that work than humans.

[00:50:26] Patrick: What are the implications of that? As you said, it's kind of hard to wrap your mind around. Does that start to mean that we just continue to collapse the frictions between I'll call it like human intent and programmable outcomes? It's almost like our imaginations become the limit rather than the elegant work.

[00:50:44] Alexandr: Yeah, that's exactly right. This is like a broad trend within software, but I think to your point, the beautiful end state is that we as people we're just going to be able to dictate into a machine learning system, what kind of software we want it to build, and it'll build something that basically accomplishes that exactly. So we can all be product managers effectively in our own mini systems. That future state, I think is like reasonably far away, maybe not infinitely far away but reasonably far away, but we're already seeing this where take these GitHub co-pilot systems. They meaningfully accelerate the programming task. There's this thing that's going to happen, where programming and product management, in some sense, we're going to keep converging where differential tasks or the differential skill is in understanding what to build rather than actually being able to build it in the first place.

[00:51:29] Patrick: It's sort of like the classic idea in machine learning that it's the label, it's the outcome that you're targeting that requires all the imagination and creativity, not the features that you're using to predict that outcome. Questions become more valuable than answers, I guess, is the other way of saying what you said, which is just, is very cool. It unlocks the core of, I guess, what makes us human, which is pretty exciting to imagine. I hope I get to live to see a lot of that happen. Alex this has been so much fun. I love this topic. I am so interested in these technologies. I think I asked the same traditional closing question of everybody. What is the kindest thing that anyone's ever done for you?

[00:52:02] Alexandr: It's not one specific action, but I think that my first violin teacher, her name is Cayenne Unum, I don't know if she'll ever listen to this, but maybe she will. Over the course of many years of working with her. I think she really instilled a few things in me. I think first, she really created a love and joy from art and creative activity and she herself, which is so incredibly joyous and very inspired and clearly loved very deeply the art and process of the creation of great music and great performance, which was just incredibly infectious. I think one learning is just that passion is incredibly infectious thing. There's a very specific moment that I remember really quite vividly, which is there's this period where I wasn't practicing very much.

And I thought I could sort like skip by or she wouldn't notice. And obviously plainly obvious to her. At one point she just ended the lesson I remember two minutes in and she said, "If you're not practicing at all, we should stop wasting your parents' money and just stop on lessons." It was like this shocking thing. I think I was in sixth or seventh grade at the time. And so I was shocked to have something so direct, be confirmed with something so direct, but I think what it really showed me, if you're going to do something, you have to do it with full passion and full force. If you're not going to do something with full passion and full force, then it probably just isn't worth doing in the first place. This has been really a driving belief behind a lot of my life. I wrote this blog post a while ago called Hire People who Give a Shit.

[00:53:34] Patrick: I remember reading it.

[00:53:34] Alexandr: Yeah. It just becomes so core to I think it's how we even hire at Scale or a lot of what we do at Scale is don't half ask. You got to do things with full force and full passion.

[00:53:41] Patrick: Absolutely love this story. One follow up question. I remember the post well and it was excellent. How do you do that? What is the most effective way to understand, not having yet worked with somebody if there's someone that gives a shit.

[00:53:51] Alexandr: One of the funny things about giving a shit, you notice it along the edges, so to speak. You notice it in maybe the depth of thought, the depth of obsession, the attention to detail, along the edges of something they really care about. I think one great example. Let's take music for example. When you're preparing a great performance, you will start noticing just the smallest fricking things and you'll just stop yourself and keep practicing until you're impeccable. All the mini flourishes and all the mini components and the way that you notice great performance is not do they get the notes right. But it's like how packable and how clearly perfect is each little detail. That's one general thing is like, I think you notice it along the edges more so than just looking full frontal at the thing itself. You can notice it by talking to people about what were the little details that you really paid attention to? Or what were the things that really bothered you about how something was being done or what were the things that took 80% of the time that other people wouldn't know notice?

That's one big thing. You'll notice it just from like the passion in people's voice and how they care. Some people express that more outwardly, some people are maybe more reserved, but you'll notice in just the care and sort of the attention by which they express those things. And then the other thing I think is from my time meeting lots of people and talking to lots of people and learning about humans in general. There are people who are generally very inspired and there are people who are generally less inspired, and the people who are more inspired you'll notice this like theme in their life. They find things that inspire them and they find the next thing that inspires and they find the next thing that inspires them, and inspires a full force and will. I think you can notice that pattern a lot when people just talk through their lives and what they've done in the past. Sometimes it's a very wide set of things. People can be inspired by punk music when they're a kid, and then they become inspired by DCFs and investing when they're an adult. But I think that just noticing that strength of will in these instances is really critical.

[00:55:45] Patrick: I think it's such a wonderful, interesting place to close that giving a shit manifests in the details and at the edges. I love that concept. I think it's so true if you ask yourself the things you're proud of producing, it's very easy to answer that question. What were the details that took all the time, and when you can't answer that question, it's probably indicative that you did a just okay job at it or didn't care that much. I just love it as a closing thought. Alex, this has been a total blast. I've learned a ton. Thank you so much for your time.

[00:56:11] Alexandr: Yeah. Thank you so much. As I mentioned, when I first chatted, I'm such a fan of the podcast, so I'm excited to be on here.

[00:56:16] Patrick: Pleasure's all mine.

This site uses cookies to improve your browsing experience. By using this site, you are consenting to this policy.
