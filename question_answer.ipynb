{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering using Embeddings\n",
    "\n",
    "based on: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in .\\env\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: typing-extensions in .\\env\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in .\\env\\lib\\site-packages (from openai) (1.4.4.220919)\n",
      "Requirement already satisfied: pandas>=1.2.3 in .\\env\\lib\\site-packages (from openai) (1.4.4)\n",
      "Requirement already satisfied: numpy in .\\env\\lib\\site-packages (from openai) (1.23.3)\n",
      "Requirement already satisfied: requests>=2.20 in .\\env\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in .\\env\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in .\\env\\lib\\site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: et-xmlfile in .\\env\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in .\\env\\lib\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\env\\lib\\site-packages (from pandas>=1.2.3->openai) (2022.2.1)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in .\\env\\lib\\site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: colorama in .\\env\\lib\\site-packages (from tqdm->openai) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in .\\env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "import pickle\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 2020 Summer Olympics men's high jump was won by Mariusz Przybylski of Poland.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gianmarco Tamberi and Mutaz Essa Barshim won the 2020 Summer Olympics men's high jump.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
    "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
    "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
    "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
    "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
    "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
    "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
    "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
    "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
    "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sjöberg\n",
    "of Sweden (1984 to 1992).\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the preprocessed document library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Antonio Gracias - Pro-Entropic Investing</th>\n",
       "      <th>Pro-Entropic Investing</th>\n",
       "      <td>Antonio Gracias is the founder, CIO, and CEO o...</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brian Schimpf - Anduril: Building The Future of Defense</th>\n",
       "      <th>Anduril's Guiding Principles and Maintaining Ethics in Defense</th>\n",
       "      <td>Patrick: I'm really interested with that as a...</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roelof Botha - Sequoia’s Crucible Moment</th>\n",
       "      <th>Re-writing the VC Rulebook</th>\n",
       "      <td>Patrick: So, Roelof, we have the pleasure of ...</td>\n",
       "      <td>4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Francis Davidson - Design-led Hospitality</th>\n",
       "      <th>Strategic Decision Making</th>\n",
       "      <td>Patrick: Especially on the modern service fro...</td>\n",
       "      <td>2828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexandr Wang - A Primer on AI</th>\n",
       "      <th>Introduction</th>\n",
       "      <td>Patrick: My guest today is Alexandr Wang, the...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 content  \\\n",
       "title                                              heading                                                                                                 \n",
       "Antonio Gracias - Pro-Entropic Investing           Pro-Entropic Investing                              Antonio Gracias is the founder, CIO, and CEO o...   \n",
       "Brian Schimpf - Anduril: Building The Future of... Anduril's Guiding Principles and Maintaining Et...   Patrick: I'm really interested with that as a...   \n",
       "Roelof Botha - Sequoia’s Crucible Moment           Re-writing the VC Rulebook                           Patrick: So, Roelof, we have the pleasure of ...   \n",
       "Francis Davidson - Design-led Hospitality          Strategic Decision Making                            Patrick: Especially on the modern service fro...   \n",
       "Alexandr Wang - A Primer on AI                     Introduction                                         Patrick: My guest today is Alexandr Wang, the...   \n",
       "\n",
       "                                                                                                       tokens  \n",
       "title                                              heading                                                     \n",
       "Antonio Gracias - Pro-Entropic Investing           Pro-Entropic Investing                                 270  \n",
       "Brian Schimpf - Anduril: Building The Future of... Anduril's Guiding Principles and Maintaining Et...    2351  \n",
       "Roelof Botha - Sequoia’s Crucible Moment           Re-writing the VC Rulebook                            4940  \n",
       "Francis Davidson - Design-led Hospitality          Strategic Decision Making                             2828  \n",
       "Alexandr Wang - A Primer on AI                     Introduction                                           195  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed.csv')\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"curie\"\n",
    "\n",
    "DOC_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-doc-001\"\n",
    "QUERY_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-query-001\"\n",
    "\n",
    "# DOC_EMBEDDINGS_MODEL = f\"text-{MODEL_NAME}-001\"\n",
    "# QUERY_EMBEDDINGS_MODEL = f\"text-{MODEL_NAME}-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, DOC_EMBEDDINGS_MODEL)\n",
    "\n",
    "def get_query_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, QUERY_EMBEDDINGS_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content.replace(\"\\n\", \" \")) for idx, r in df.iterrows()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_by_token_max(input_str: str, max_tokens: int):\n",
    "    max_chars = max_tokens * 4\n",
    "    output_str = input_str\n",
    "\n",
    "    if len(input_str) > max_chars:\n",
    "        # print('length of input str:' + str(len(input_str)))\n",
    "        output_str = input_str[:max_chars]\n",
    "        # print('length of output str:' + str(len(output_str)))\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Gabriel Leydon - How Web3 Onboards a Billion Users</th>\n",
       "      <th>Introduction</th>\n",
       "      <td>Patrick: My guest today is Gabe Leydon, whose...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Free-to-Own Gaming</th>\n",
       "      <td>Patrick: All right, Gabe, so it's been almost...</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three Waves of NFTs</th>\n",
       "      <td>Patrick: Can you say a little bit about this ...</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  content  \\\n",
       "title                                              heading                                                                  \n",
       "Gabriel Leydon - How Web3 Onboards a Billion Users Introduction          Patrick: My guest today is Gabe Leydon, whose...   \n",
       "                                                   Free-to-Own Gaming    Patrick: All right, Gabe, so it's been almost...   \n",
       "                                                   Three Waves of NFTs   Patrick: Can you say a little bit about this ...   \n",
       "\n",
       "                                                                        tokens  \n",
       "title                                              heading                      \n",
       "Gabriel Leydon - How Web3 Onboards a Billion Users Introduction            183  \n",
       "                                                   Free-to-Own Gaming     2536  \n",
       "                                                   Three Waves of NFTs    1517  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].apply(lambda x: truncate_by_token_max(x, 2000))\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk size: 100\n",
      "computing doc embeddings for chunk 1 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 2 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 3 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 4 of 4\n",
      "sleeping 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def rate_limit(input_df: pd.DataFrame, limit: int):\n",
    "\n",
    "    print('chunk size: ' + str(limit))\n",
    "\n",
    "    df_list = []\n",
    "    if input_df.shape[0] > limit: \n",
    "\n",
    "        for start in range(0, len(input_df), limit):\n",
    "            df_list.append(input_df[start:start+limit])\n",
    "\n",
    "    else:\n",
    "        df_list.append(input_df)\n",
    "\n",
    "    output_list = []\n",
    "    counter = 1\n",
    "    for chunk_df in df_list:\n",
    "\n",
    "        print('computing doc embeddings for chunk {} of {}'.format(str(counter), str(len(df_list))))\n",
    "        output_list.append(compute_doc_embeddings(chunk_df))\n",
    "\n",
    "        print('sleeping 60 seconds')\n",
    "        time.sleep(60)\n",
    "        counter = counter + 1\n",
    "\n",
    "    out_dict = {}\n",
    "    for result_dict in output_list:\n",
    "        out_dict.update(result_dict)\n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n",
    "\n",
    "# context_embeddings = rate_limit(df[:60], 30)\n",
    "context_embeddings = rate_limit(df, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Introduction'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Free-to-Own Gaming'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Three Waves of NFTs'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'DigiDaigaku'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'NFTs Ability to Change Marketing')]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save dictionary to pickle file\n",
    "with open('context_embeddings.pickle', 'wb') as file:\n",
    "    pickle.dump(context_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# load a pickle file\n",
    "with open(\"context_embeddings.pickle\", \"rb\") as file:\n",
    "    document_embeddings = pickle.load(file)\n",
    "# display the dictionary\n",
    "print(list(document_embeddings.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    We could use cosine similarity or dot product to calculate the similarity between vectors.\n",
    "    In practice, we have found it makes little difference. \n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.42707484151104347,\n",
       "  ('Matthew Ball - A Manual to The Metaverse',\n",
       "   'Familiar Platforms with Metaverse Elements')),\n",
       " (0.42434117795735227,\n",
       "  ('Matthew Ball - A Manual to The Metaverse', 'Introduction')),\n",
       " (0.4020909055483938,\n",
       "  ('Bill Gurley, Philip Rosedale - Back to the Future',\n",
       "   'Defining The \"Metaverse\"')),\n",
       " (0.396451047957024,\n",
       "  ('Matthew Ball - A Manual to The Metaverse',\n",
       "   'Potential Future Winners and Losers')),\n",
       " (0.3925489225813553,\n",
       "  ('Bill Gurley, Philip Rosedale - Back to the Future',\n",
       "   'What the Metaverse is Missing'))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What is the Metaverse?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3117111566851345,\n",
       "  ('Frank Slootman - Narrow the Focus, Increase the Quality', 'Introduction')),\n",
       " (0.29772308833550654,\n",
       "  ('Lydia Jett - Investing in E-commerce',\n",
       "   'Vertical Integration and Margins')),\n",
       " (0.29598255044345195,\n",
       "  ('Josh Wolfe, Chris Power - Factories of the Future',\n",
       "   'Understanding The Demand & Supply Forces At Play')),\n",
       " (0.2944527728683338,\n",
       "  ('Alex Rampell - Investing in Operating Systems',\n",
       "   'Think in Terms of Bonds and Call Options, Not Equity')),\n",
       " (0.29319102786965845,\n",
       "  ('Martin Casado - The Past, Present, and Future of Digital Infrastructure',\n",
       "   'The Biggest Innovations This Cycle'))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What is a vertical cloud?\", document_embeddings)[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 5000\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Familiar Platforms with Metaverse Elements')\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Introduction')\n",
      "===\n",
      " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "*  Patrick: Well, round two is here. We get to talk about one of the most interesting topics in the world, especially because of how much insane detail there is under the topic of the metaverse, much of it contained in your awesome new book that I just finished a couple days ago. I think a fun place to begin picking up on our last conversation is with a couple analogy questions, specifically around things that already exist that people will be familiar with, and the degree to which you think they represent something like the metaverse. I want to start here as an anchor point, rather than go deep into the infrastructure right from the beginning. So I'd love you to stack rank these four big ideas, and you tell me which you think from most to least represents metaverse elements. Those four being Minecraft, Ready Player One, Fortnite, and Facebook's Horizon. Matthew: So let me swerve quickly. I would say that the closest representation that we have comes from one platform that you didn't list, and then another perspective on one that you did. Roblox for all of its focus on children, they have 55 million daily active users. About 45% of them are under 13, 85% of them are under 25 lacks many of the things that we expect from the metaverse certainly enterprise applications. Certainly a degree of criticality in the modern economy at large. But we're talking about a platform that has hundreds of millions of monthly users, billions of hours of engagement, in excess of 75 million different virtual worlds. Each of which is tightly integrated with one another. Consistent communications, hierarchy in access. The same avatar and identity system, same currency, import/export of objects, a single path of discovery. We're talking about a parallel plane of existence that is simultaneously enormous and highly diverse, but also cohesive. The second closest would be to take a look at the Epic Games ecosystem. We can really take a look at two different aspects of that on the consumer facing side. One is Fortnite, which is for the most part a battle royale. But they also have Fortnite Creative Mode, which is their Roblox platform.What's fascinating about that latter platform, which by the way, they say is nearly half of all engagement time today, is that later this year, they're planning to bring Unreal based editing. So this is going to fundamentally overhaul how you can tool, author, modify. You have the consumer-facing low or no code platform that children could use, but then you can tap into the million plus expert developers who can supplement that with their professional capabilities. On top of that, you have the broader Unreal ecosystem. And this is where we start to talk about interoperability at large, the application of consistent backends, common file formats, consistent communication suites that spans 75% of next generation games, numerous different automotive platforms, an increasingly large footprint in architecture engineering construction, or the ACE field. To focus on Fortnite, to focus even on Fortnite Creative Mode is too small. What makes this opportunity and this ecosystem so much larger than Roblox is that it's already deployed widely in many different use cases. The connective tissue isn't yet in place. But when we're talking about the closest template to the metaverse in the future, that ecosystem looks primed. Patrick: You didn't say Facebook horizons. By the time it made its announcement, its name change, it was one of the largest companies in the world by market cap. Tons of free cash flow, tons of ability to invest. Tons of demonstrated will to invest. Huge amount of CapEx going into this with obviously one of the most interesting entrepreneurs in the world behind it. What do you make of their foray into trying to own this concept literally by changing their name to it? And why wasn't it in your top two? Matthew: First and foremost, one of the interesting evolutions in Mark's perspective has actually been publicly revealed on the record. Let's start a decade ago or so. There's a lot of focus on the metaverse as a term today, but it's clear that Mark has been running towards this for quite some time. Their second most expensive acquisition, actually third after WhatsApp and Instagram, was for Oculus nearly a decade ago. Another billion or $2 billion acquisition was that of control labs and electromyography interface and hardware company. It actually picks up electro skeletal muscle signals so that you can reproduce movements in virtual space. We know in 2015, he was looking to acquire Unity, the most widely deployed game engine globally. So this is something that he's clearly been interested in for quite some time. We also know from leaks in 2018 that there were internal memos saying that the metaverse was, \"Theirs to lose.\" What has changed over the past four years is not just more investment, more aggression, a philosophical realignment of the business. But they are a lot more focused on the interoperable metaverse. And I actually think that that's sincere. We see this in their app store policies, they support side loading, third-party identities. They're the only major console platform to use third-party or open rendering APIs. OpenXR, WebXR, all of the consoles reject them. So we see a evolution of what they're trying to do and how they're trying to participate in the world that is different. But for all of that lineage, you're right to say that they are not top one or top two. Horizon Worlds is their effort to build a Roblox or Fortnite Creative Mode or Minecraft. What I call an integrated virtual world platform. It's not very popular today.Now they say that by the end of the year, they will launch a web browser based version, bringing instantaneous access to billions on the planet. Right now, the biggest impediment for any event in Roblox, or Minecraft, or Fortnite is that if you don't already have the 50 or 60 gigabyte installer on a device, you don't currently use it, there's a lot of friction. My mother's not going to instantly download it to participate in the Malcolm Gladwell event. But when it's browser based, when it's easy to use, when your entire social graph is there, there's some potential there. But this platform remains relatively modest. When you're talking about the billions that they are spending per animal, Horizon Worlds is a part of that. When you take a look at the full stack, they are of course investing billions in hardware design, AR and VR. We know that that's also moving into semis. We know that they're also investing in their own operating system. And then on top of that, we have the investments in content. Beat Saber, Population One, their battle royale, as well as into Horizon Worlds and many other pet projects around wearables and so forth. Horizon Worlds seems like one of the biggest opportunities. It has not historically been their focus, at least as relates to the metaverse. Patrick: Can you just define what you mean by the metaverse and what you think a good working definition is that allows us to test things to say, is this thing that everyone's excited about, or is it not? It seems obvious from our many conversations that the trend has been towards more digital engagement and participation. And that somehow, people think of the metaverse as the natural endpoint of this, where there's more sensory immersion in some virtual world, there's more navigability, there's less walled gardens. How do you define the metaverse in its simplest definition so that we can all work off the same idea? Matthew: A live 3D version of the internet as we know today is the best and simplest way to think about this. Why? Because it not only explains how it's a little bit different visually experientially. It keys into some of what you just mentioned, which is how it might be more intuitive. Of course, we didn't evolve for thousands of years to tap glass, to interact with 2D interfaces, static information. We explore, we immerse in \n",
      "*  Patrick: My guest today is Matthew Ball. Matt is an investor, the former head of strategy at Amazon Studios, and one of the brightest minds in the media industry. Through his essays and now his book which launches today, Matt has established himself as the foremost authority on the metaverse, which has stormed into the public eye since I first had him on the show two years ago. The metaverse is the focus for our discussion, and I hope you enjoy this encyclopedic tour through all of its details as much as I did.\n",
      "\n",
      " Q: What is the Metaverse?\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"What is the Metaverse?\",\n",
    "    document_embeddings,\n",
    "    df\n",
    ")\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Familiar Platforms with Metaverse Elements')\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A live 3D version of the internet as we know today is the best and simplest way to think about this.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What is the Metaverse?\", df, document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Alexandr Wang - A Primer on AI', 'Building the AWS of the Future')\n",
      "('Alexandr Wang - A Primer on AI', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ScaleAI makes money by providing data solutions to leading AI teams. These solutions help the teams to produce high quality data, which is essential for AI models.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"How does ScaleAI make money?\", df, document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Alexandr Wang - A Primer on AI', 'Building the AWS of the Future')\n",
      "('Alexandr Wang - A Primer on AI', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ScaleAI sells a product that helps companies produce high quality data sets for their machine learning algorithms.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What product does ScaleAI sell?\", df, document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 document sections:\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Software Investing Philosophy')\n",
      "('Martin Casado - The Past, Present, and Future of Digital Infrastructure', 'Case Studies on Public Cloud Computing')\n",
      "('Frank Slootman - Narrow the Focus, Increase the Quality', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"What is vertical SaaS?\", df, document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 document sections:\n",
      "('Garry Tan - Unwrapping the Gift', 'Evaluating Ideas and People')\n",
      "('Katherine Boyle - Investing for America', 'Introduction')\n",
      "('Garry Tan - Unwrapping the Gift', 'The Most Common Bad Ideas')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_query_with_context(\"?\", df, document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0879c91d05bdbbd22a80c643c00cc9a8f17eac70366bc0d4907821b249e2eb50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
