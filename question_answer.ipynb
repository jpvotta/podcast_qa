{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering using Embeddings\n",
    "\n",
    "based on: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "\n",
    "In this notebook, we experiment with asking GPT-3 to answer questions using a library of podcast transcripts as a reference. We achieve this by using document embeddings and retrieval as an intermediate step in the question-answer process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in .\\env\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: typing-extensions in .\\env\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: requests>=2.20 in .\\env\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in .\\env\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in .\\env\\lib\\site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: pandas>=1.2.3 in .\\env\\lib\\site-packages (from openai) (1.4.4)\n",
      "Requirement already satisfied: numpy in .\\env\\lib\\site-packages (from openai) (1.23.3)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in .\\env\\lib\\site-packages (from openai) (1.4.4.220919)\n",
      "Requirement already satisfied: et-xmlfile in .\\env\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in .\\env\\lib\\site-packages (from pandas>=1.2.3->openai) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in .\\env\\lib\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: types-pytz>=2022.1.1 in .\\env\\lib\\site-packages (from pandas-stubs>=1.1.0.11->openai) (2022.2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in .\\env\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: colorama in .\\env\\lib\\site-packages (from tqdm->openai) (0.4.5)\n",
      "Requirement already satisfied: six>=1.5 in .\\env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installs\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "import pickle\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that I use a config file to store my API keys.\n",
    "import config\n",
    "# openai.api_key = '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'\n",
    "\n",
    "openai.api_key = config.openai_apikey\n",
    "# or, use openai.api_key = 'your-api-key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivating Example\n",
    "\n",
    "From the sample notebook: `By default, GPT-3 isn't an expert on the 2020 Olympics:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The 2020 Summer Olympics men's high jump was won by Mariusz Przybylski of Poland.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a business question I'd like to answer: How does ScaleAI make money?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: How does ScaleAI make money?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sample notebook: `Mariusz Przybylski is a professional footballer from Poland, and not much of a high jumper! Evidently GPT-3 needs some assistance here.`\n",
    "\n",
    "`The first issue to tackle is that the model is hallucinating an answer rather than telling us \"I don't know\". This is bad because it makes it hard to trust the answer that the model gives us!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, I don't know.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sample notebook: `To help the model answer the question, we provide extra contextual information in the prompt. When the total required context is short, we can include it in the prompt directly. For example we can use this information taken from Wikipedia. We update the initial prompt to tell the model to explicitly make use of the provided text.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gianmarco Tamberi and Mutaz Essa Barshim won the 2020 Summer Olympics men's high jump.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question as truthfully as possible using the provided text, and if the answer is not contained within the text below, say \"I don't know\"\n",
    "\n",
    "Context:\n",
    "The men's high jump event at the 2020 Summer Olympics took place between 30 July and 1 August 2021 at the Olympic Stadium.\n",
    "33 athletes from 24 nations competed; the total possible number depended on how many nations would use universality places \n",
    "to enter athletes in addition to the 32 qualifying through mark or ranking (no universality places were used in 2021).\n",
    "Italian athlete Gianmarco Tamberi along with Qatari athlete Mutaz Essa Barshim emerged as joint winners of the event following\n",
    "a tie between both of them as they cleared 2.37m. Both Tamberi and Barshim agreed to share the gold medal in a rare instance\n",
    "where the athletes of different nations had agreed to share the same medal in the history of Olympics. \n",
    "Barshim in particular was heard to ask a competition official \"Can we have two golds?\" in response to being offered a \n",
    "'jump off'. Maksim Nedasekau of Belarus took bronze. The medals were the first ever in the men's high jump for Italy and \n",
    "Belarus, the first gold in the men's high jump for Italy and Qatar, and the third consecutive medal in the men's high jump\n",
    "for Qatar (all by Barshim). Barshim became only the second man to earn three medals in high jump, joining Patrik Sj√∂berg\n",
    "of Sweden (1984 to 1992).\n",
    "\n",
    "Q: Who won the 2020 Summer Olympics men's high jump?\n",
    "A:\"\"\"\n",
    "\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the podcast data\n",
    "\n",
    "To replicate something like the structure of the above (where we help the algorithm \"zoom in\" on a specific body of text from which to pull the answer), we are going to use the following process:\n",
    "- compare the word embedding vector of the query (i.e. \"what is the metaverse?\") to the word embedding vector of each podcast section and compute similarity (akin to dot product or cosine similarity)\n",
    "- select the highest-ranked one or couple of candidate word embedding vectors, subject to a character/token limit\n",
    "- pass the selected section text as an addendum to the query to help the model answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 rows in the data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Martin Casado - The Past, Present, and Future of Digital Infrastructure</th>\n",
       "      <th>Exciting Possibilities Offered By Digital Infrastructure</th>\n",
       "      <td>Patrick: And as you think about the ways that...</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John Pfeffer - Adapt and Evolve</th>\n",
       "      <th>Sources of Capital Efficiency and Value Creation</th>\n",
       "      <td>Patrick: Why would that be good? Thinking abo...</td>\n",
       "      <td>2877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eric Mandelblatt - Investing in the Industrial Economy</th>\n",
       "      <th>How a Commodities Business Operates</th>\n",
       "      <td>Patrick: All right, so maybe we could shift n...</td>\n",
       "      <td>2662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dmitry Balyasny - Building a Better Model</th>\n",
       "      <th>Outperforming with Multiple Investing Groups and Strategies</th>\n",
       "      <td>Patrick: Maybe you can just describe in some ...</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenneth Stanley - Greatness Without Goals</th>\n",
       "      <th>The Story of Picbreeder</th>\n",
       "      <td>Patrick: In the book and in the presentation ...</td>\n",
       "      <td>3929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 content  \\\n",
       "title                                              heading                                                                                                 \n",
       "Martin Casado - The Past, Present, and Future o... Exciting Possibilities Offered By Digital Infra...   Patrick: And as you think about the ways that...   \n",
       "John Pfeffer - Adapt and Evolve                    Sources of Capital Efficiency and Value Creation     Patrick: Why would that be good? Thinking abo...   \n",
       "Eric Mandelblatt - Investing in the Industrial ... How a Commodities Business Operates                  Patrick: All right, so maybe we could shift n...   \n",
       "Dmitry Balyasny - Building a Better Model          Outperforming with Multiple Investing Groups an...   Patrick: Maybe you can just describe in some ...   \n",
       "Kenneth Stanley - Greatness Without Goals          The Story of Picbreeder                              Patrick: In the book and in the presentation ...   \n",
       "\n",
       "                                                                                                       tokens  \n",
       "title                                              heading                                                     \n",
       "Martin Casado - The Past, Present, and Future o... Exciting Possibilities Offered By Digital Infra...    1278  \n",
       "John Pfeffer - Adapt and Evolve                    Sources of Capital Efficiency and Value Creation      2877  \n",
       "Eric Mandelblatt - Investing in the Industrial ... How a Commodities Business Operates                   2662  \n",
       "Dmitry Balyasny - Building a Better Model          Outperforming with Multiple Investing Groups an...    2489  \n",
       "Kenneth Stanley - Greatness Without Goals          The Story of Picbreeder                               3929  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv('preprocessed.csv')\n",
    "df = df.set_index([\"title\", \"heading\"])\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "print(f\"{len(df)} rows in the data.\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models used:\n",
    "- `text-search-curie-query-001`: for embedding the search query\n",
    "- `text-search-curie-doc-001`: for embedding the documents to be retrieved (constructing a 4096-dimensional word embedding vector)\n",
    "\n",
    "More information: `https://beta.api.openai.org/docs/guides/embeddings/what-are-embeddings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"curie\"\n",
    "\n",
    "DOC_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-doc-001\"\n",
    "QUERY_EMBEDDINGS_MODEL = f\"text-search-{MODEL_NAME}-query-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions as defined in the sample notebook\n",
    "\n",
    "def get_embedding(text: str, model: str) -> list[float]:\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "\n",
    "def get_doc_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, DOC_EMBEDDINGS_MODEL)\n",
    "\n",
    "def get_query_embedding(text: str) -> list[float]:\n",
    "    return get_embedding(text, QUERY_EMBEDDINGS_MODEL)\n",
    "\n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> dict[tuple[str, str], list[float]]:\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        idx: get_doc_embedding(r.content.replace(\"\\n\", \" \")) for idx, r in df.iterrows()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We truncate each podcast section to a maximum of 2,000 tokens (i.e. around 8,000 characters). If I were to repeat this exercise, I might consider breaking the podcasts into more granular chunks (such as each interviewer question + the guest's answer). For now, the truncation seems to work okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to truncate each section (text string) up to a configurable number of tokens\n",
    "\n",
    "def truncate_by_token_max(input_str: str, max_tokens: int):\n",
    "    max_chars = max_tokens * 4\n",
    "    output_str = input_str\n",
    "\n",
    "    if len(input_str) > max_chars:\n",
    "        # print('length of input str:' + str(len(input_str)))\n",
    "        output_str = input_str[:max_chars]\n",
    "        # print('length of output str:' + str(len(output_str)))\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>heading</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Gabriel Leydon - How Web3 Onboards a Billion Users</th>\n",
       "      <th>Introduction</th>\n",
       "      <td>Patrick: My guest today is Gabe Leydon, whose...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Free-to-Own Gaming</th>\n",
       "      <td>Patrick: All right, Gabe, so it's been almost...</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Three Waves of NFTs</th>\n",
       "      <td>Patrick: Can you say a little bit about this ...</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DigiDaigaku</th>\n",
       "      <td>Patrick: Can you tell the story then of Digi,...</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFTs Ability to Change Marketing</th>\n",
       "      <td>Patrick: One of the things that jumps out of ...</td>\n",
       "      <td>4623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI, Innovation, &amp; The Future</th>\n",
       "      <td>Patrick: It's exciting that some emotive resp...</td>\n",
       "      <td>3464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Harley Finkelstein - Building the Entrepreneurship Company</th>\n",
       "      <th>Introduction</th>\n",
       "      <td>Patrick: My guest today is Harley Finkelstein...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finding Your Life's Work</th>\n",
       "      <td>Patrick: So Harley, maybe the place to begin ...</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Entrepreneurial Formula</th>\n",
       "      <td>Patrick: If you think about your just hands-o...</td>\n",
       "      <td>3096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delivering and Applying Good Advice in Business</th>\n",
       "      <td>Patrick: One of the things I'm obviously obse...</td>\n",
       "      <td>1833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              content  \\\n",
       "title                                              heading                                                                                              \n",
       "Gabriel Leydon - How Web3 Onboards a Billion Users Introduction                                      Patrick: My guest today is Gabe Leydon, whose...   \n",
       "                                                   Free-to-Own Gaming                                Patrick: All right, Gabe, so it's been almost...   \n",
       "                                                   Three Waves of NFTs                               Patrick: Can you say a little bit about this ...   \n",
       "                                                   DigiDaigaku                                       Patrick: Can you tell the story then of Digi,...   \n",
       "                                                   NFTs Ability to Change Marketing                  Patrick: One of the things that jumps out of ...   \n",
       "                                                   AI, Innovation, & The Future                      Patrick: It's exciting that some emotive resp...   \n",
       "Harley Finkelstein - Building the Entrepreneurs... Introduction                                      Patrick: My guest today is Harley Finkelstein...   \n",
       "                                                   Finding Your Life's Work                          Patrick: So Harley, maybe the place to begin ...   \n",
       "                                                   The Entrepreneurial Formula                       Patrick: If you think about your just hands-o...   \n",
       "                                                   Delivering and Applying Good Advice in Business   Patrick: One of the things I'm obviously obse...   \n",
       "\n",
       "                                                                                                    tokens  \n",
       "title                                              heading                                                  \n",
       "Gabriel Leydon - How Web3 Onboards a Billion Users Introduction                                        183  \n",
       "                                                   Free-to-Own Gaming                                 2536  \n",
       "                                                   Three Waves of NFTs                                1517  \n",
       "                                                   DigiDaigaku                                        2411  \n",
       "                                                   NFTs Ability to Change Marketing                   4623  \n",
       "                                                   AI, Innovation, & The Future                       3464  \n",
       "Harley Finkelstein - Building the Entrepreneurs... Introduction                                        110  \n",
       "                                                   Finding Your Life's Work                           3006  \n",
       "                                                   The Entrepreneurial Formula                        3096  \n",
       "                                                   Delivering and Applying Good Advice in Business    1833  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].apply(lambda x: truncate_by_token_max(x, 2000))\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Document Embeddings\n",
    "\n",
    "NOTE: I needed to sign up for an API key in order to run the below code for the full dataset - it cost approximately $6 (see pricing: `https://openai.com/api/pricing/`).\n",
    "\n",
    "If you are replicating this analysis with a free account, the included backoff (process 30 sections every 60 sections) should adhere to the free tier rate limits if you are processing a smaller dataset.\n",
    "\n",
    "To avoid computing the doc embeddings yourself, simply skip the below code block. (I saved the result in `context_embeddings.pickle`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk size: 100\n",
      "computing doc embeddings for chunk 1 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 2 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 3 of 4\n",
      "sleeping 60 seconds\n",
      "computing doc embeddings for chunk 4 of 4\n",
      "sleeping 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# script to chunk the dataframe being passed to the compute_doc_embeddings() method\n",
    "def rate_limit(input_df: pd.DataFrame, limit: int):\n",
    "\n",
    "    # chunk the dataframe into a list of dfs\n",
    "    print('chunk size: ' + str(limit))\n",
    "    df_list = []\n",
    "    if input_df.shape[0] > limit: \n",
    "\n",
    "        for start in range(0, len(input_df), limit):\n",
    "            df_list.append(input_df[start:start+limit])\n",
    "\n",
    "    else:\n",
    "        df_list.append(input_df)\n",
    "\n",
    "    # make a list to collect the output of the compute_doc_embeddings() method\n",
    "    output_list = []\n",
    "    counter = 1\n",
    "    for chunk_df in df_list:\n",
    "\n",
    "        # compute the doc embeddings\n",
    "        print('computing doc embeddings for chunk {} of {}'.format(str(counter), str(len(df_list))))\n",
    "        output_list.append(compute_doc_embeddings(chunk_df))\n",
    "\n",
    "        print('sleeping 60 seconds')\n",
    "        time.sleep(60)\n",
    "        counter = counter + 1\n",
    "\n",
    "    # merge the list of dictionaries\n",
    "    out_dict = {}\n",
    "    for result_dict in output_list:\n",
    "        out_dict.update(result_dict)\n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n",
    "\n",
    "# run the above method for 100 at a time (any config should work if you have an API key and have attached a credit card)\n",
    "context_embeddings = rate_limit(df, 100)\n",
    "\n",
    "import pickle\n",
    "\n",
    "# save dictionary to pickle file\n",
    "with open('context_embeddings.pickle', 'wb') as file:\n",
    "    pickle.dump(context_embeddings, file, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Introduction'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Free-to-Own Gaming'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'Three Waves of NFTs'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'DigiDaigaku'), ('Gabriel Leydon - How Web3 Onboards a Billion Users', 'NFTs Ability to Change Marketing')]\n"
     ]
    }
   ],
   "source": [
    "# load a pickle file\n",
    "with open(\"context_embeddings.pickle\", \"rb\") as file:\n",
    "    document_embeddings = pickle.load(file)\n",
    "# display the dictionary\n",
    "print(list(document_embeddings.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions borrowed from the example notebook\n",
    "\n",
    "def vector_similarity(x: list[float], y: list[float]) -> float:\n",
    "    \"\"\"\n",
    "    We could use cosine similarity or dot product to calculate the similarity between vectors.\n",
    "    In practice, we have found it makes little difference. \n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict[(str, str), np.array]) -> list[(float, (str, str))]:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_query_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Similarity Scoring of Query vs Embeddings\n",
    "\n",
    "Let's evaluate the \"most similar\" documents (podcast sections) relative to the query \"What is the Metaverse?\".\n",
    "\n",
    "I chose the above query because I am expecting the model to return a section of the Matthew Ball episode in which he provides a good definition of the Metaverse.\n",
    "\n",
    "As expected, the podcast titled 'Matthew Ball - A Manual to The Metaverse' is ranked 1st, 2nd, and 4th. I didn't check the sections specifically but at a high level, the similarity scoring seems to be working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.42707484151104347,\n",
       "  ('Matthew Ball - A Manual to The Metaverse',\n",
       "   'Familiar Platforms with Metaverse Elements')),\n",
       " (0.42434117795735227,\n",
       "  ('Matthew Ball - A Manual to The Metaverse', 'Introduction')),\n",
       " (0.4020909055483938,\n",
       "  ('Bill Gurley, Philip Rosedale - Back to the Future',\n",
       "   'Defining The \"Metaverse\"')),\n",
       " (0.396451047957024,\n",
       "  ('Matthew Ball - A Manual to The Metaverse',\n",
       "   'Potential Future Winners and Losers')),\n",
       " (0.3925489225813553,\n",
       "  ('Bill Gurley, Philip Rosedale - Back to the Future',\n",
       "   'What the Metaverse is Missing'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"What is the Metaverse?\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 5000\n",
    "SEPARATOR = \"\\n* \"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "separator_len = len(tokenizer.tokenize(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Prompts\n",
    "\n",
    "Now, we can construct a prompt according to the following structure:\n",
    "- anti-hallucination block (\"answer as truthfully as possible\")\n",
    "- the context (union of as many relevant podcast sections as we can fit subject to max section length)\n",
    "- the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Familiar Platforms with Metaverse Elements')\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Introduction')\n",
      "===\n",
      " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "*  Patrick: Well, round two is here. We get to talk about one of the most interesting topics in the world, especially because of how much insane detail there is under the topic of the metaverse, much of it contained in your awesome new book that I just finished a couple days ago. I think a fun place to begin picking up on our last conversation is with a couple analogy questions, specifically around things that already exist that people will be familiar with, and the degree to which you think they represent something like the metaverse. I want to start here as an anchor point, rather than go deep into the infrastructure right from the beginning. So I'd love you to stack rank these four big ideas, and you tell me which you think from most to least represents metaverse elements. Those four being Minecraft, Ready Player One, Fortnite, and Facebook's Horizon. Matthew: So let me swerve quickly. I would say that the closest representation that we have comes from one platform that you didn't list, and then another perspective on one that you did. Roblox for all of its focus on children, they have 55 million daily active users. About 45% of them are under 13, 85% of them are under 25 lacks many of the things that we expect from the metaverse certainly enterprise applications. Certainly a degree of criticality in the modern economy at large. But we're talking about a platform that has hundreds of millions of monthly users, billions of hours of engagement, in excess of 75 million different virtual worlds. Each of which is tightly integrated with one another. Consistent communications, hierarchy in access. The same avatar and identity system, same currency, import/export of objects, a single path of discovery. We're talking about a parallel plane of existence that is simultaneously enormous and highly diverse, but also cohesive. The second closest would be to take a look at the Epic Games ecosystem. We can really take a look at two different aspects of that on the consumer facing side. One is Fortnite, which is for the most part a battle royale. But they also have Fortnite Creative Mode, which is their Roblox platform.What's fascinating about that latter platform, which by the way, they say is nearly half of all engagement time today, is that later this year, they're planning to bring Unreal based editing. So this is going to fundamentally overhaul how you can tool, author, modify. You have the consumer-facing low or no code platform that children could use, but then you can tap into the million plus expert developers who can supplement that with their professional capabilities. On top of that, you have the broader Unreal ecosystem. And this is where we start to talk about interoperability at large, the application of consistent backends, common file formats, consistent communication suites that spans 75% of next generation games, numerous different automotive platforms, an increasingly large footprint in architecture engineering construction, or the ACE field. To focus on Fortnite, to focus even on Fortnite Creative Mode is too small. What makes this opportunity and this ecosystem so much larger than Roblox is that it's already deployed widely in many different use cases. The connective tissue isn't yet in place. But when we're talking about the closest template to the metaverse in the future, that ecosystem looks primed. Patrick: You didn't say Facebook horizons. By the time it made its announcement, its name change, it was one of the largest companies in the world by market cap. Tons of free cash flow, tons of ability to invest. Tons of demonstrated will to invest. Huge amount of CapEx going into this with obviously one of the most interesting entrepreneurs in the world behind it. What do you make of their foray into trying to own this concept literally by changing their name to it? And why wasn't it in your top two? Matthew: First and foremost, one of the interesting evolutions in Mark's perspective has actually been publicly revealed on the record. Let's start a decade ago or so. There's a lot of focus on the metaverse as a term today, but it's clear that Mark has been running towards this for quite some time. Their second most expensive acquisition, actually third after WhatsApp and Instagram, was for Oculus nearly a decade ago. Another billion or $2 billion acquisition was that of control labs and electromyography interface and hardware company. It actually picks up electro skeletal muscle signals so that you can reproduce movements in virtual space. We know in 2015, he was looking to acquire Unity, the most widely deployed game engine globally. So this is something that he's clearly been interested in for quite some time. We also know from leaks in 2018 that there were internal memos saying that the metaverse was, \"Theirs to lose.\" What has changed over the past four years is not just more investment, more aggression, a philosophical realignment of the business. But they are a lot more focused on the interoperable metaverse. And I actually think that that's sincere. We see this in their app store policies, they support side loading, third-party identities. They're the only major console platform to use third-party or open rendering APIs. OpenXR, WebXR, all of the consoles reject them. So we see a evolution of what they're trying to do and how they're trying to participate in the world that is different. But for all of that lineage, you're right to say that they are not top one or top two. Horizon Worlds is their effort to build a Roblox or Fortnite Creative Mode or Minecraft. What I call an integrated virtual world platform. It's not very popular today.Now they say that by the end of the year, they will launch a web browser based version, bringing instantaneous access to billions on the planet. Right now, the biggest impediment for any event in Roblox, or Minecraft, or Fortnite is that if you don't already have the 50 or 60 gigabyte installer on a device, you don't currently use it, there's a lot of friction. My mother's not going to instantly download it to participate in the Malcolm Gladwell event. But when it's browser based, when it's easy to use, when your entire social graph is there, there's some potential there. But this platform remains relatively modest. When you're talking about the billions that they are spending per animal, Horizon Worlds is a part of that. When you take a look at the full stack, they are of course investing billions in hardware design, AR and VR. We know that that's also moving into semis. We know that they're also investing in their own operating system. And then on top of that, we have the investments in content. Beat Saber, Population One, their battle royale, as well as into Horizon Worlds and many other pet projects around wearables and so forth. Horizon Worlds seems like one of the biggest opportunities. It has not historically been their focus, at least as relates to the metaverse. Patrick: Can you just define what you mean by the metaverse and what you think a good working definition is that allows us to test things to say, is this thing that everyone's excited about, or is it not? It seems obvious from our many conversations that the trend has been towards more digital engagement and participation. And that somehow, people think of the metaverse as the natural endpoint of this, where there's more sensory immersion in some virtual world, there's more navigability, there's less walled gardens. How do you define the metaverse in its simplest definition so that we can all work off the same idea? Matthew: A live 3D version of the internet as we know today is the best and simplest way to think about this. Why? Because it not only explains how it's a little bit different visually experientially. It keys into some of what you just mentioned, which is how it might be more intuitive. Of course, we didn't evolve for thousands of years to tap glass, to interact with 2D interfaces, static information. We explore, we immerse in \n",
      "*  Patrick: My guest today is Matthew Ball. Matt is an investor, the former head of strategy at Amazon Studios, and one of the brightest minds in the media industry. Through his essays and now his book which launches today, Matt has established himself as the foremost authority on the metaverse, which has stormed into the public eye since I first had him on the show two years ago. The metaverse is the focus for our discussion, and I hope you enjoy this encyclopedic tour through all of its details as much as I did.\n",
      "\n",
      " Q: What is the Metaverse?\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"What is the Metaverse?\",\n",
    "    document_embeddings,\n",
    "    df\n",
    ")\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict[(str, str), np.array],\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Answers\n",
    "\n",
    "Finally, let's test out the question-answer system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Familiar Platforms with Metaverse Elements')\n",
      "('Matthew Ball - A Manual to The Metaverse', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A live 3D version of the internet as we know today is the best and simplest way to think about this.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pretty decent answer\n",
    "\n",
    "answer_query_with_context(\"What is the Metaverse?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Alexandr Wang - A Primer on AI', 'Building the AWS of the Future')\n",
      "('Alexandr Wang - A Primer on AI', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ScaleAI makes money by providing data solutions to leading AI teams. These solutions help the teams to produce high quality data, which is essential for AI models.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another decent answer\n",
    "\n",
    "answer_query_with_context(\"How does ScaleAI make money?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Alexandr Wang - A Primer on AI', 'Building the AWS of the Future')\n",
      "('Alexandr Wang - A Primer on AI', 'Introduction')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ScaleAI sells a product that helps companies produce high quality data sets for their machine learning algorithms.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was trying to probe for something like: \"ScaleAI makes money by providing data labeling services to AI companies\" - possibly need to do a bit more work to get there.\n",
    "\n",
    "# still not bad, though.\n",
    "\n",
    "answer_query_with_context(\"What product does ScaleAI sell?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Introduction')\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Opportunity Set vs. Capital Flows')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Thoma Bravo invests in software and technology businesses. It was Orlando who led the firm's early entry into software buyouts some 20 years ago, and he has overseen more than 350 software acquisitions since.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was trying to probe for something like: \"ScaleAI makes money by providing data labeling services to AI companies\" - possibly need to do a bit more work to get there.\n",
    "\n",
    "# still not bad, though.\n",
    "\n",
    "answer_query_with_context(\"What is Thoma Bravo's investment strategy?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 3 document sections:\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Introduction')\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Opportunity Set vs. Capital Flows')\n",
      "('Orlando Bravo - The Art of Software Buyouts', 'Private Equity & Future Return Potential')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Orlando Bravo's investment strategy is to buy the market leaders of today in the software industry.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I was trying to probe for something like: \"ScaleAI makes money by providing data labeling services to AI companies\" - possibly need to do a bit more work to get there.\n",
    "\n",
    "# still not bad, though.\n",
    "\n",
    "answer_query_with_context(\"What is Orlando Bravo's investment strategy?\", df, document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # freeze a requirements file for the project\n",
    "# %pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0879c91d05bdbbd22a80c643c00cc9a8f17eac70366bc0d4907821b249e2eb50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
